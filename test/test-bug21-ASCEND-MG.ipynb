{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d6ff664",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "# 定义矩阵乘法\n",
    "\n",
    "\n",
    "def apply_clover(Vin, op):\n",
    "    Vout = np.zeros(Vin.shape, dtype=Vin.dtype)\n",
    "    Vout = np.einsum('...ab,...b->...a', op.clover, Vin)\n",
    "    return Vout\n",
    "\n",
    "\n",
    "def apply_hopping_x_p(Vin, op):\n",
    "    Vout = np.zeros(Vin.shape, dtype=Vin.dtype)\n",
    "    Vout = (np.einsum('...ab,...b->...a',\n",
    "            op.hopping[0, :], np.roll(Vin, -1, axis=0)))\n",
    "    return Vout\n",
    "\n",
    "\n",
    "def apply_hopping_x_m(Vin, op):\n",
    "    Vout = np.zeros(Vin.shape, dtype=Vin.dtype)\n",
    "    Vout = (np.einsum('...ab,...b->...a',\n",
    "            op.hopping[1, :], np.roll(Vin, 1, axis=0)))\n",
    "    return Vout\n",
    "\n",
    "\n",
    "def apply_hopping_y_p(Vin, op):\n",
    "    Vout = np.zeros(Vin.shape, dtype=Vin.dtype)\n",
    "    Vout = (np.einsum('...ab,...b->...a',\n",
    "            op.hopping[2, :], np.roll(Vin, -1, axis=1)))\n",
    "    return Vout\n",
    "\n",
    "\n",
    "def apply_hopping_y_m(Vin, op):\n",
    "    Vout = np.zeros(Vin.shape, dtype=Vin.dtype)\n",
    "    Vout = (np.einsum('...ab,...b->...a',\n",
    "            op.hopping[3, :], np.roll(Vin, 1, axis=1)))\n",
    "    return Vout\n",
    "\n",
    "\n",
    "def apply_hopping(Vin, op):\n",
    "    Vout = np.zeros(Vin.shape, dtype=Vin.dtype)\n",
    "    Vout = apply_hopping_x_p(Vin, op) + apply_hopping_x_m(Vin, op) + \\\n",
    "        apply_hopping_y_p(Vin, op) + apply_hopping_y_m(Vin, op)\n",
    "    return Vout\n",
    "\n",
    "\n",
    "def apply_mat(Vin, op):\n",
    "    Vin = apply_clover(Vin, op) + apply_hopping(Vin, op)\n",
    "    return Vin\n",
    "# 格点参数\n",
    "\n",
    "\n",
    "class operator_para:\n",
    "    nx = 0\n",
    "    ny = 0\n",
    "    nc = 0\n",
    "    volume = 0\n",
    "    if_fine = 0\n",
    "    hopping = np.zeros((4, nx, ny, nc, nc*2)).view(np.complex128)\n",
    "    clover = np.zeros((nx, ny, nc, nc*2)).view(np.complex128)\n",
    "\n",
    "    def __init__(self, nx, ny, nc=2, U=0, if_fine=0):\n",
    "        self.nx = nx\n",
    "        self.ny = ny\n",
    "        self.nc = nc\n",
    "        self.U = U\n",
    "        self.volume = nx*ny\n",
    "        self.if_fine = if_fine\n",
    "        self.hopping = np.zeros((4, nx, ny, nc, nc*2)).view(np.complex128)\n",
    "        self.clover = np.zeros((nx, ny, nc, nc*2)).view(np.complex128)\n",
    "        # print(f\"(nx, ny, nc, nc):{(nx, ny, nc, nc)}\")\n",
    "        # print(f\"self.clover.shape:{self.clover.shape}\")\n",
    "        # print(f\"self.clover.dtype:{self.clover.dtype}\")\n",
    "        # exit()\n",
    "        for i in range(0, self.nc):\n",
    "            self.clover[:, :, i, i] = 1\n",
    "        if self.if_fine != 0:\n",
    "            print(self.hopping.shape)\n",
    "            ma = -0.4  # -0.4375\n",
    "            kappa = -1/(2*(ma + 4))\n",
    "            self.hopping[0, :] = kappa*np.roll(self.U[0, :], -1, axis=0)  # x+\n",
    "            self.hopping[1, :] = kappa * \\\n",
    "                np.conj(self.U[0, :]).transpose(0, 1, 3, 2)  # x-\n",
    "            self.hopping[2, :] = kappa*np.roll(self.U[1, :], -1, axis=1)  # y+\n",
    "            self.hopping[3, :] = kappa * \\\n",
    "                np.conj(self.U[1, :]).transpose(0, 1, 3, 2)  # y-\n",
    "\n",
    "\n",
    "# 生成组态U\n",
    "# SU(2)\n",
    "# 定义 Pauli 矩阵\n",
    "sigma1 = np.array([[0, 1], [1, 0]], dtype=complex)\n",
    "sigma2 = np.array([[0, -1j], [1j, 0]], dtype=complex)\n",
    "sigma3 = np.array([[1, 0], [0, -1]], dtype=complex)\n",
    "eye = np.array([[1, 0], [0, 1]], dtype=complex)\n",
    "pauli = [sigma1, sigma2, sigma3]\n",
    "\n",
    "\n",
    "def generate_E_m_su2_u1():\n",
    "    a = np.random.randn(1)  # U(1)\n",
    "    E_m_su2 = eye-sigma1\n",
    "    return a*E_m_su2\n",
    "\n",
    "\n",
    "def generate_E_p_su2_u1():\n",
    "    a = np.random.randn(1)  # U(1)\n",
    "    E_m_su2 = eye+sigma1\n",
    "    return a*E_m_su2\n",
    "\n",
    "\n",
    "def generate_E_m_su2_u1_2():\n",
    "    a = np.random.randn(1)  # U(1)\n",
    "    E_m_su2 = eye-sigma2\n",
    "    return a*E_m_su2\n",
    "\n",
    "\n",
    "def generate_E_p_su2_u1_2():\n",
    "    a = np.random.randn(1)  # U(1)\n",
    "    E_m_su2 = eye+sigma2\n",
    "    return a*E_m_su2\n",
    "\n",
    "\n",
    "def generate_large_matrix(x, y, nc):\n",
    "    \"\"\"\n",
    "    生成形状为 (x, y, 2, 2) 的矩阵，每个 (2, 2) 子矩阵是随机的 SU(2) 矩阵。\n",
    "    参数：\n",
    "        x (int): 第一维的大小\n",
    "        y (int): 第二维的大小\n",
    "    返回：\n",
    "        numpy.ndarray: 形状为 (x, y, 2, 2) 的复数矩阵\n",
    "    \"\"\"\n",
    "    # 初始化大矩阵\n",
    "    large_matrix = np.zeros((4, x, y, nc, nc), dtype=np.complex128)\n",
    "    if (nc == 2):\n",
    "        large_matrix[0, :, :] = generate_E_m_su2_u1()\n",
    "        large_matrix[1, :, :] = generate_E_p_su2_u1()\n",
    "        large_matrix[2, :, :] = generate_E_m_su2_u1_2()\n",
    "        large_matrix[3, :, :] = generate_E_p_su2_u1_2()\n",
    "    return large_matrix\n",
    "# 生成或读取组态U\n",
    "\n",
    "\n",
    "def load_or_generate_U(nx, ny, nc, folder_path=\".\"):\n",
    "    \"\"\"\n",
    "    检查文件夹下是否有U_nx_ny_nc.npy文件，若存在则读取，否则生成并保存。\n",
    "    参数：\n",
    "    nx, ny, nc: 用于构造文件名和生成U的参数\n",
    "    folder_path: 文件夹路径，默认为当前目录\n",
    "    返回：\n",
    "    U: CuPy complex128数组\n",
    "    \"\"\"\n",
    "    # 构造文件名\n",
    "    file_name = f\"U_{nx}_{ny}_{nc}.npy\"\n",
    "    file_path = os.path.join(folder_path, file_name)\n",
    "    # 检查文件是否存在\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"找到文件 {file_name}，正在加载...\")\n",
    "        # 读取NumPy数组并转换为CuPy数组\n",
    "        U_np = np.load(file_path)\n",
    "        U = np.array(U_np, dtype=np.complex128)\n",
    "    else:\n",
    "        print(f\"未找到文件 {file_name}，正在生成...\")\n",
    "        # 调用aaa函数生成U\n",
    "        U = generate_large_matrix(nx, ny, nc)\n",
    "        # 确保U是complex128类型\n",
    "        U = U.astype(np.complex128)\n",
    "        # 将CuPy数组转换为NumPy数组以保存\n",
    "        U_np = U\n",
    "        # 保存到文件\n",
    "        np.save(file_path, U_np)\n",
    "        print(f\"已保存文件 {file_name}\")\n",
    "    return U\n",
    "\n",
    "\n",
    "class cg_info:\n",
    "    count = 0\n",
    "    norm_r = 0\n",
    "    r = 0\n",
    "    if_max_iter = 0\n",
    "\n",
    "\n",
    "def bicgstab(b, x0=None, op=None, max_iter=3000, tol=1e-8, if_info=0, info=cg_info(), relative_tol=0):\n",
    "    \"\"\"\n",
    "    使用BiCGSTAB方法求解 Ax = b，其中矩阵A的乘法操作被替换为 apply_mat(V, op)。\n",
    "    参数：\n",
    "    - lattice: 具有 apply_mat 方法的 lattice 对象。\n",
    "    - b: 右侧向量。\n",
    "    - x0: 初始解（默认为零向量）。\n",
    "    - op: apply_mat 的操作参数。\n",
    "    - max_iter: 最大迭代次数。\n",
    "    - tol: 收敛容差。\n",
    "    返回：\n",
    "    - x: 解向量。\n",
    "    \"\"\"\n",
    "    # 初始化解向量 x\n",
    "    if x0 is None:\n",
    "        x = np.zeros_like(b)\n",
    "    else:\n",
    "        x = x0.copy()\n",
    "    # 计算初始残差 r = b - Ax\n",
    "    r = b - apply_mat(x, op)\n",
    "    if relative_tol != 0:\n",
    "        tol = np.vdot(r, r)*relative_tol\n",
    "    # print(r)\n",
    "    r0 = r.copy()  # 保存初始残差 r0\n",
    "    p = r.copy()   # 初始化搜索方向 p\n",
    "    alpha = 1\n",
    "    count = 0\n",
    "    # 主迭代循环\n",
    "    for k in range(max_iter):\n",
    "        count += 1\n",
    "        # 计算 Ap = A * p\n",
    "        Ap = apply_mat(p, op)\n",
    "        # 计算步长 alpha\n",
    "        alpha = np.vdot(r0, r) / np.vdot(r0, Ap)\n",
    "        # print(\"alpha = \", alpha)\n",
    "        x += alpha * p\n",
    "        # 更新中间残差 r_1 = r - alpha * Ap\n",
    "        r_1 = r - alpha * Ap\n",
    "        # 检查是否收敛\n",
    "        if if_info != 0:\n",
    "            print(np.vdot(r_1, r_1))\n",
    "        if np.vdot(r_1, r_1) < tol:\n",
    "            if if_info != 0:\n",
    "                print(\"count = \", count)\n",
    "            info.count = count\n",
    "            info.norm_r = np.vdot(r_1, r_1)\n",
    "            info.r = r_1\n",
    "            return x\n",
    "        # 计算 t = A * r\n",
    "        t = apply_mat(r, op)\n",
    "        # 计算 omega\n",
    "        omega = np.vdot(t, r) / np.vdot(t, t)\n",
    "        # 更新解 x\n",
    "        x += omega * r_1\n",
    "        # 更新残差 r = r_1 - omega * t\n",
    "        r_1 = r_1 - omega * apply_mat(r_1, op)\n",
    "        # 检查是否收敛\n",
    "        if np.vdot(r, r) < tol:\n",
    "            if if_info != 0:\n",
    "                print(\"count = \", count)\n",
    "            info.count = count\n",
    "            info.norm_r = np.vdot(r_1, r_1)\n",
    "            info.r = r_1\n",
    "            return x\n",
    "        # 计算 beta\n",
    "        beta = (np.vdot(r_1, r_1) / np.vdot(r, r))\n",
    "        # 更新搜索方向 p\n",
    "        p = r_1 + alpha*beta/omega*p - alpha*beta*Ap\n",
    "        r = r_1\n",
    "    # 如果未收敛，抛出错误\n",
    "    print(\"over max_iter\")\n",
    "    info.if_max_iter = 1\n",
    "    return x\n",
    "\n",
    "\n",
    "class mg:\n",
    "    blocksize = [4, 2, 2, 2, 2, 2]  # 每一层的单个方向的压缩程度\n",
    "    coarse_dof = [8, 12, 12, 12, 12, 12]  # 新一层的内禀维度\n",
    "    R_null_vec = []\n",
    "    mg_ops = []\n",
    "    coarse_map = []\n",
    "    fine_sites_per_coarse_list = []\n",
    "    convergence_history = []\n",
    "    # 生成近零空间向量\n",
    "\n",
    "    def near_null_vec(self, P_null_vec_coarse, coarse_dof, coarse_op, info=cg_info()):\n",
    "        for i in range(0, coarse_dof):\n",
    "            # 施密特正交化\n",
    "            for k in range(0, i):\n",
    "                P_null_vec_coarse[i, :, :, :] -= np.vdot((P_null_vec_coarse[k, :, :, :]), P_null_vec_coarse[i, :, :, :])/np.vdot(\n",
    "                    (P_null_vec_coarse[k, :, :, :]), P_null_vec_coarse[k, :, :, :])*P_null_vec_coarse[k, :, :, :]\n",
    "            # Ar\n",
    "            Ar = apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)\n",
    "            # -Ar\n",
    "            Ar = -Ar\n",
    "            # x = (A^-1)*(-Ar)\n",
    "            x = bicgstab(Ar, op=coarse_op, tol=5e-5, info=info)\n",
    "            # V = x+r\n",
    "            P_null_vec_coarse[i, :, :, :] += x\n",
    "            # 施密特正交化\n",
    "            for k in range(0, i):\n",
    "                P_null_vec_coarse[i, :, :, :] -= np.vdot((P_null_vec_coarse[k, :, :, :]), P_null_vec_coarse[i, :, :, :])/np.vdot(\n",
    "                    (P_null_vec_coarse[k, :, :, :]), P_null_vec_coarse[k, :, :, :])*P_null_vec_coarse[k, :, :, :]\n",
    "            P_null_vec_coarse[i, :] = P_null_vec_coarse[i, :] / \\\n",
    "                np.sqrt(\n",
    "                    np.vdot((P_null_vec_coarse[i, :]), P_null_vec_coarse[i, :]))\n",
    "            print(\n",
    "                f\"(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:{(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]}\")\n",
    "        return P_null_vec_coarse\n",
    "\n",
    "    def vol_index_dof_to_cv_index(self, i, i_dof, coarse_op):\n",
    "        return coarse_op.nc*i + i_dof\n",
    "\n",
    "    def index_to_coord(self, ptr, coarse_op):\n",
    "        y_coarse = ptr % coarse_op.ny\n",
    "        x_coarse = ptr // coarse_op.ny\n",
    "        return x_coarse, y_coarse\n",
    "    # 网格物理地址与内存地址转化\n",
    "\n",
    "    def coord_to_index(self, coords, coarse_op, i):\n",
    "        ptr = (coarse_op.ny*coords[0] + coords[1])*coarse_op.nc + i\n",
    "        return ptr\n",
    "\n",
    "    def zeros_like_fermi(self, level):\n",
    "        fermi_out = np.random.rand(\n",
    "            self.mg_ops[level].nx, self.mg_ops[level].ny, self.mg_ops[level].nc*2).view(np.complex128)\n",
    "        fermi_out = np.zeros_like(fermi_out)\n",
    "        return fermi_out\n",
    "    '''\n",
    "    建立粗网格与细网格之间的对应关系\n",
    "    '''\n",
    "\n",
    "    def build_mapping(self, map_id, fine_op, coarse_op):\n",
    "        print(\"Buliding map...\")\n",
    "        for i in range(0, coarse_op.volume):\n",
    "            x_coarse, y_coarse = self.index_to_coord(i, coarse_op)\n",
    "            coarse_coords = [x_coarse, y_coarse]\n",
    "            coords = [0, 0]\n",
    "            blocksizes = int(fine_op.nx/coarse_op.nx)\n",
    "            count = [0]\n",
    "            self.recursive_site_build(\n",
    "                map_id, coarse_coords, coords, 0, count, blocksizes, fine_op, i)\n",
    "        print(\"Buliding map finished\")\n",
    "    '''\n",
    "    build_mapping用到的递归函数\n",
    "    '''\n",
    "\n",
    "    def recursive_site_build(self, map_id, coarse_coords, coords, step, count, blocksizes, fine_op, fine_ptr):\n",
    "        if (step < 2):\n",
    "            for i in range(coarse_coords[step]*blocksizes, (coarse_coords[step]+1)*blocksizes):\n",
    "                coords[step] = i\n",
    "                self.recursive_site_build(\n",
    "                    map_id, coarse_coords, coords, step+1, count, blocksizes, fine_op, fine_ptr)\n",
    "        else:\n",
    "            for i in range(0, fine_op.nc):\n",
    "                self.coarse_map[map_id][fine_ptr][count[0]\n",
    "                                                  ] = self.coord_to_index(coords, fine_op, i)\n",
    "                count[0] = count[0] + 1\n",
    "\n",
    "    def restrict_f2c(self, fine_level, fermi_in, fermi_out):\n",
    "        fine_sites_per_coarse = self.fine_sites_per_coarse_list[fine_level]\n",
    "        nevc = self.coarse_dof[fine_level]\n",
    "        fermi_in = fermi_in.reshape(-1)\n",
    "        fermi_out = fermi_out.reshape(-1)\n",
    "        for i in range(0, self.mg_ops[fine_level+1].volume):\n",
    "            for i_dof in range(0, nevc):\n",
    "                cv_index = self.vol_index_dof_to_cv_index(\n",
    "                    i, i_dof, self.mg_ops[fine_level+1])\n",
    "                for j in range(0, fine_sites_per_coarse):\n",
    "                    fermi_out[cv_index] += np.conj(self.R_null_vec[fine_level][i_dof]\n",
    "                                                   [self.coarse_map[fine_level][i][j]])*fermi_in[self.coarse_map[fine_level][i][j]]\n",
    "\n",
    "    def prolong_c2f(self, fine_level, fermi_in, fermi_out):\n",
    "        fine_sites_per_coarse = self.fine_sites_per_coarse_list[fine_level]\n",
    "        nevc = self.coarse_dof[fine_level]\n",
    "        fermi_in = fermi_in.reshape(-1)\n",
    "        fermi_out = fermi_out.reshape(-1)\n",
    "        for i in range(0, self.mg_ops[fine_level+1].volume):\n",
    "            for i_dof in range(0, nevc):\n",
    "                cv_index = self.vol_index_dof_to_cv_index(\n",
    "                    i, i_dof, self.mg_ops[fine_level+1])\n",
    "                for j in range(0, fine_sites_per_coarse):\n",
    "                    fermi_out[self.coarse_map[fine_level][i][j]\n",
    "                              ] += self.R_null_vec[fine_level][i_dof][self.coarse_map[fine_level][i][j]]*fermi_in[cv_index]\n",
    "\n",
    "    def local_orthogonalization(self, fine_level, nevc, fine_sites_per_coarse):\n",
    "        for i in range(0, self.mg_ops[fine_level+1].volume):\n",
    "            for i_dof in range(0, nevc):\n",
    "                for k in range(0, i_dof):\n",
    "                    k_dot = 0\n",
    "                    k_i_dof_dot = 0\n",
    "                    for j in range(0, fine_sites_per_coarse):\n",
    "                        k_dot += np.conj(self.R_null_vec[fine_level][k][self.coarse_map[fine_level][i][j]]) * \\\n",
    "                            self.R_null_vec[fine_level][k][self.coarse_map[fine_level][i][j]]\n",
    "                        k_i_dof_dot += np.conj(self.R_null_vec[fine_level][k][self.coarse_map[fine_level][i][j]]) * \\\n",
    "                            self.R_null_vec[fine_level][i_dof][self.coarse_map[fine_level][i][j]]\n",
    "                    for j in range(0, fine_sites_per_coarse):\n",
    "                        self.R_null_vec[fine_level][i_dof][self.coarse_map[fine_level][i][j]\n",
    "                                                           ] -= self.R_null_vec[fine_level][k][self.coarse_map[fine_level][i][j]] * k_i_dof_dot / k_dot\n",
    "                i_dof_dot = 0\n",
    "                for j in range(0, fine_sites_per_coarse):\n",
    "                    i_dof_dot += np.conj(self.R_null_vec[fine_level][i_dof][self.coarse_map[fine_level][i][j]]) * \\\n",
    "                        self.R_null_vec[fine_level][i_dof][self.coarse_map[fine_level][i][j]]\n",
    "                for j in range(0, fine_sites_per_coarse):\n",
    "                    self.R_null_vec[fine_level][i_dof][self.coarse_map[fine_level]\n",
    "                                                       [i][j]] /= np.sqrt(i_dof_dot)\n",
    "\n",
    "    def __init__(self, fine_op, n_refine, ifeigen=0):\n",
    "        self.n_refine = n_refine\n",
    "        self.fine_op = fine_op\n",
    "        U = self.fine_op.U\n",
    "        nx = self.fine_op.nx\n",
    "        ny = self.fine_op.ny\n",
    "        nc = self.fine_op.nc\n",
    "        if (ifeigen == 0):\n",
    "            print(\"搭建多重网格...\")\n",
    "            self.mg_ops.append(fine_op)\n",
    "            for i in range(0, n_refine):\n",
    "                print(\"当前层： \", i)\n",
    "                print(\"创造近零空间向量...\")\n",
    "                for s in range(10):\n",
    "                    info_null_vec = cg_info()\n",
    "                    P_null_vec_coarse = np.random.rand(\n",
    "                        self.coarse_dof[i], nx, ny, nc*2).view(np.complex128)\n",
    "                    P_null_vec_coarse = self.near_null_vec(\n",
    "                        P_null_vec_coarse, self.coarse_dof[i], self.mg_ops[i], info=info_null_vec)\n",
    "                    if (info_null_vec.if_max_iter == 0):\n",
    "                        break\n",
    "                P_null_vec_coarse = P_null_vec_coarse.reshape(\n",
    "                    P_null_vec_coarse.shape[0], -1)\n",
    "                self.R_null_vec.append(P_null_vec_coarse)\n",
    "                print(\"近零空间向量创造完毕\")\n",
    "                rand_fermi = np.random.rand(nx, ny, nc*2).view(np.complex128)\n",
    "                rand_fermi = np.zeros_like(rand_fermi)\n",
    "                rand_fermi = np.ones_like(rand_fermi)\n",
    "                nx = int(nx/self.blocksize[i])\n",
    "                ny = int(ny/self.blocksize[i])\n",
    "                nc_c = nc\n",
    "                nc = int(self.coarse_dof[i])\n",
    "                map = [[int(0)]*int(self.blocksize[i] *\n",
    "                                    self.blocksize[i]*nc_c)] * int(nx*ny)\n",
    "                fine_sites_per_coarse = int(\n",
    "                    self.blocksize[i]*self.blocksize[i]*nc_c)\n",
    "                self.fine_sites_per_coarse_list.append(fine_sites_per_coarse)\n",
    "                map = np.array(map)\n",
    "                self.coarse_map.append(map)\n",
    "                coarse_op = operator_para(nx, ny, nc)\n",
    "                self.mg_ops.append(coarse_op)\n",
    "                self.build_mapping(i, self.mg_ops[i], self.mg_ops[i+1])\n",
    "                self.local_orthogonalization(\n",
    "                    i, self.coarse_dof[i], fine_sites_per_coarse)\n",
    "                fermi_out = np.random.rand(nx, ny, nc*2).view(np.complex128)\n",
    "                fermi_out = self.zeros_like_fermi(i+1)\n",
    "                fermi_out = np.zeros_like(fermi_out)\n",
    "                fermi_out = fermi_out\n",
    "                fermi_out_r = np.zeros_like(rand_fermi)\n",
    "                print(\"生成更粗一层对角元与非对角元...\")\n",
    "                ################################# transfer ######################################\n",
    "                self.mg_ops[i +\n",
    "                            1].clover = np.zeros_like(self.mg_ops[i+1].clover)\n",
    "                # clover\n",
    "                for color in range(0, self.mg_ops[i+1].nc):\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[:, :, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_clover(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].clover[:, :, :,\n",
    "                                            color] = fermi_tmp_coarse[:, :, :]\n",
    "                # wilson\n",
    "                self.mg_ops[i +\n",
    "                            1].hopping = np.zeros_like(self.mg_ops[i+1].hopping)\n",
    "                for color in range(0, self.mg_ops[i+1].nc):\n",
    "                    # xp=even\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[0:-1:2, :, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_hopping_x_p(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].hopping[0, 1::2, :, :,\n",
    "                                             color] = fermi_tmp_coarse[1::2, :, :]\n",
    "                    self.mg_ops[i+1].clover[0:-1:2, :, :,\n",
    "                                            color] += fermi_tmp_coarse[0:-1:2, :, :]\n",
    "                    # xp=odd\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[1::2, :, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_hopping_x_p(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].hopping[0, 0:-1:2, :, :,\n",
    "                                             color] = fermi_tmp_coarse[0:-1:2, :, :]\n",
    "                    self.mg_ops[i+1].clover[1::2, :, :,\n",
    "                                            color] += fermi_tmp_coarse[1::2, :, :]\n",
    "                    # xm=even\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[0:-1:2, :, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_hopping_x_m(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].hopping[1, 1::2, :, :,\n",
    "                                             color] = fermi_tmp_coarse[1::2, :, :]\n",
    "                    self.mg_ops[i+1].clover[0:-1:2, :, :,\n",
    "                                            color] += fermi_tmp_coarse[0:-1:2, :, :]\n",
    "                    # xm=odd\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[1::2, :, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_hopping_x_m(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].hopping[1, 0:-1:2, :, :,\n",
    "                                             color] = fermi_tmp_coarse[0:-1:2, :, :]\n",
    "                    self.mg_ops[i+1].clover[1::2, :, :,\n",
    "                                            color] += fermi_tmp_coarse[1::2, :, :]\n",
    "                    # yp=even\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[:, 0:-1:2, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_hopping_y_p(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].hopping[2, :, 1::2, :,\n",
    "                                             color] = fermi_tmp_coarse[:, 1::2, :]\n",
    "                    self.mg_ops[i+1].clover[:, 0:-1:2, :,\n",
    "                                            color] += fermi_tmp_coarse[:, 0:-1:2, :]\n",
    "                    # yp=odd\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[:, 1::2, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_hopping_y_p(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].hopping[2, :, 0:-1:2, :,\n",
    "                                             color] = fermi_tmp_coarse[:, 0:-1:2, :]\n",
    "                    self.mg_ops[i+1].clover[:, 1::2, :,\n",
    "                                            color] += fermi_tmp_coarse[:, 1::2, :]\n",
    "                    # ym=even\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[:, 0:-1:2, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_hopping_y_m(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].hopping[3, :, 1::2, :,\n",
    "                                             color] = fermi_tmp_coarse[:, 1::2, :]\n",
    "                    self.mg_ops[i+1].clover[:, 0:-1:2, :,\n",
    "                                            color] += fermi_tmp_coarse[:, 0:-1:2, :]\n",
    "                    # ym=odd\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                    fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                    fermi_tmp_coarse[:, 1::2, color] = 1\n",
    "                    self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                    fermi_tmp_Afine = apply_hopping_y_m(\n",
    "                        fermi_tmp_fine, self.mg_ops[i])\n",
    "                    fermi_tmp_coarse = np.zeros_like(fermi_tmp_coarse)\n",
    "                    self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse)\n",
    "                    self.mg_ops[i+1].hopping[3, :, 0:-1:2, :,\n",
    "                                             color] = fermi_tmp_coarse[:, 0:-1:2, :]\n",
    "                    self.mg_ops[i+1].clover[:, 1::2, :,\n",
    "                                            color] += fermi_tmp_coarse[:, 1::2, :]\n",
    "                fermi_tmp_coarse = np.zeros_like(fermi_out)\n",
    "                fermi_tmp_fine = np.zeros_like(fermi_out_r)\n",
    "                fermi_tmp_Afine = np.zeros_like(fermi_out_r)\n",
    "                fermi_tmp_coarse_n = np.zeros_like(fermi_out)\n",
    "                fermi_tmp_coarse_t = np.zeros_like(fermi_out)\n",
    "                fermi_tmp_coarse[:, :, 0] = 1\n",
    "                fermi_tmp_coarse_n = apply_mat(\n",
    "                    fermi_tmp_coarse, self.mg_ops[i+1])\n",
    "                self.prolong_c2f(i, fermi_tmp_coarse, fermi_tmp_fine)\n",
    "                fermi_tmp_Afine = apply_mat(\n",
    "                    fermi_tmp_fine, self.mg_ops[i])\n",
    "                self.restrict_f2c(i, fermi_tmp_Afine, fermi_tmp_coarse_t)\n",
    "                print(\"dif = \", np.linalg.norm(\n",
    "                    fermi_tmp_coarse_n-fermi_tmp_coarse_t))\n",
    "\n",
    "    def mg_bicgstab_recursive(self, b, max_iter=300, tol=1e-10, if_info=1, info=cg_info(), level=0, relative_tol=0):\n",
    "        x = np.zeros_like(b)\n",
    "        if level < self.n_refine+1:\n",
    "            # 计算初始残差 r = b - Ax\n",
    "            r = b - apply_mat(x, self.mg_ops[level])\n",
    "            if relative_tol != 0:\n",
    "                tol = np.sqrt(np.vdot(r, r))*relative_tol\n",
    "            r0 = r.copy()  # 保存初始残差 r0\n",
    "            p = r.copy()   # 初始化搜索方向 p\n",
    "            alpha = 1\n",
    "            count = 0\n",
    "            if if_info != 0:\n",
    "                print(\" \"*(level), \"level = \", level, np.sqrt(np.vdot(r, r)))\n",
    "            # 主迭代循环\n",
    "            for k in range(max_iter):\n",
    "                count += 1\n",
    "                # 计算 Ap = A * p\n",
    "                Ap = apply_mat(p, self.mg_ops[level])\n",
    "                # 计算步长 alpha\n",
    "                alpha = np.vdot((r0), r) / np.vdot((r0), Ap)\n",
    "                x += alpha * p\n",
    "                # 更新中间残差 r_1 = r - alpha * Ap\n",
    "                r_1 = r - alpha * Ap\n",
    "                # 检查是否收敛\n",
    "                if if_info != 0:\n",
    "                    print(\" \"*(level), \"level = \", level,\n",
    "                          np.sqrt(np.vdot(r_1, r_1)))\n",
    "                if np.sqrt(np.vdot(r_1, r_1)) < tol:\n",
    "                    if if_info != 0:\n",
    "                        print(\" \"*(level), \"level = \", level, \"RelRes\", np.sqrt(\n",
    "                            np.vdot(r_1, r_1))/np.sqrt(np.vdot(r0, r0)))\n",
    "                    info.count = count\n",
    "                    info.norm_r = np.sqrt(np.vdot(r_1, r_1))\n",
    "                    info.r = r_1\n",
    "                    return x\n",
    "                # 计算 t = A * r\n",
    "                t = apply_mat(r, self.mg_ops[level])\n",
    "                # 计算 omega\n",
    "                omega = np.vdot((t), r) / np.vdot((t), t)\n",
    "                # 更新解 x\n",
    "                x += omega * r_1\n",
    "                # 更新残差 r = r_1 - omega * t\n",
    "                r_1 = r_1 - omega * apply_mat(r_1, self.mg_ops[level])\n",
    "                if level == 0:\n",
    "                    r_norm = np.linalg.norm(b - apply_mat(x, self.mg_ops[0]))\n",
    "                    self.convergence_history.append(r_norm)\n",
    "                    print(\n",
    "                        f\"{k}_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):{r_norm}\")\n",
    "                if level < self.n_refine:\n",
    "                    # 下潜\n",
    "                    r_coarse = self.zeros_like_fermi(level=level+1)\n",
    "                    self.restrict_f2c(level, r_1, r_coarse)\n",
    "                    # 递归\n",
    "                    info_c = cg_info()\n",
    "                    relative_tol = 0.25\n",
    "                    if level+1 == self.n_refine:\n",
    "                        e_coarse = self.mg_bicgstab_recursive(\n",
    "                            r_coarse, level=level+1, info=info_c, relative_tol=0.1, if_info=0, max_iter=100)\n",
    "                    else:\n",
    "                        e_coarse = self.mg_bicgstab_recursive(\n",
    "                            r_coarse, level=level+1, info=info_c, relative_tol=0.25, if_info=1, max_iter=100)\n",
    "                    print(\" \"*(level+1), \"level\", level +\n",
    "                          1, \" \", \"iter\", info_c.count)\n",
    "                    # 上浮\n",
    "                    e0_fine = self.zeros_like_fermi(level=level)\n",
    "                    self.prolong_c2f(level, e_coarse, e0_fine)\n",
    "                    if info_c.if_max_iter == 0:  # ?\n",
    "                        x = x + e0_fine\n",
    "                        r_1 = b - apply_mat(x, self.mg_ops[level])\n",
    "                if level == 0:\n",
    "                    r_norm = np.linalg.norm(b - apply_mat(x, self.mg_ops[0]))\n",
    "                    self.convergence_history.append(r_norm)\n",
    "                    print(\n",
    "                        f\"{k}_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):{r_norm}\")\n",
    "                # 检查是否收敛\n",
    "                if np.sqrt(np.vdot(r_1, r_1)) < tol:\n",
    "                    if if_info != 0:\n",
    "                        print(\" \"*(level), \"level = \", level, \"RelRes\", np.sqrt(\n",
    "                            np.vdot(r_1, r_1))/np.sqrt(np.vdot(r0, r0)))\n",
    "                    info.count = count\n",
    "                    info.norm_r = np.sqrt(np.vdot(r_1, r_1))\n",
    "                    info.r = r_1\n",
    "                    return x\n",
    "                # 计算 beta\n",
    "                beta = (np.vdot((r_1), r_1) / np.vdot((r), r))\n",
    "                # 更新搜索方向 p\n",
    "                p = r_1 + alpha*beta/omega*p - alpha*beta*Ap\n",
    "                r = r_1\n",
    "            # 如果未收敛，抛出错误\n",
    "            print(\" \"*(level), \"level\", level, \"over max_iter\")\n",
    "            info.if_max_iter = 1\n",
    "            return x\n",
    "        if level == 0:\n",
    "            print(\"level = \", level, \"   \")\n",
    "\n",
    "    def mg_bicgstab(self, b, max_iter=3000, tol=1e-10,  info=cg_info()):\n",
    "\n",
    "        X = self.mg_bicgstab_recursive(\n",
    "            b, max_iter=max_iter, tol=tol, info=info, level=0, relative_tol=0)\n",
    "        print(\"mg_bicgstab_recursive.count = \", info.count)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    def plot(self):\n",
    "        import matplotlib.pyplot as plt\n",
    "        import numpy as np\n",
    "        np.Inf = np.inf\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.title(\n",
    "            f\"(self.mg_ops[0].nx,self.mg_ops[0].ny,self.mg_ops[0].nc:{self.mg_ops[0].nx,self.mg_ops[0].ny,self.mg_ops[0].nc})convergence_history(self.coarse_dof:{self.coarse_dof})\", fontsize=16)\n",
    "        plt.semilogy(range(1, len(self.convergence_history) + 1),\n",
    "                     self.convergence_history, 'b-o', markersize=4, linewidth=2)\n",
    "        plt.xlabel(\n",
    "            f\"Iteration\", fontsize=12)\n",
    "        plt.ylabel('Residual Norm', fontsize=12)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e9b2909",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到文件 U_64_64_2.npy，正在加载...\n",
      "生成的矩阵形状： (4, 64, 64, 2, 2)\n",
      "(4, 64, 64, 2, 2)\n",
      "(326.352287103584+0j)\n",
      "(9.555910200664522+0j)\n",
      "(1.9491769106653138+0j)\n",
      "(0.4031514032761271+0j)\n",
      "(0.1863690141516607+0j)\n",
      "(1.9094534819006919+0j)\n",
      "(1.564895525357082+0j)\n",
      "(585.3409721344644+0j)\n",
      "(0.8164755415459715+0j)\n",
      "(0.358034587662571+0j)\n",
      "(0.17481948827808197+0j)\n",
      "(0.525406293662329+0j)\n",
      "(0.1806616657037189+0j)\n",
      "(0.8314327208412362+0j)\n",
      "(0.5295069435333604+0j)\n",
      "(0.1517536787204019+0j)\n",
      "(0.19976279036839506+0j)\n",
      "(0.10999476796560911+0j)\n",
      "(0.11996419986973418+0j)\n",
      "(0.0416305198778315+0j)\n",
      "(0.027916511553921053+0j)\n",
      "(0.019579017161122817+0j)\n",
      "(0.0174347643926033+0j)\n",
      "(0.005968606631233959+0j)\n",
      "(0.005478193754944424+0j)\n",
      "(0.003835360827963049+0j)\n",
      "(0.003476611458419202+0j)\n",
      "(0.0032404629840218856+0j)\n",
      "(0.0031445902282655072+0j)\n",
      "(0.0005834953367985696+0j)\n",
      "(0.0005204296130561116+0j)\n",
      "(0.00039637658328817523+0j)\n",
      "(0.0003734924382550279+0j)\n",
      "(0.00031950580218533366+0j)\n",
      "(0.00030234920860606324+0j)\n",
      "(0.0002911301792888796+0j)\n",
      "(0.00014697198010332388+0j)\n",
      "(0.00014221725499212104+0j)\n",
      "(6.475868944927301e-05+0j)\n",
      "(5.34181940460424e-05+0j)\n",
      "(4.760964785746563e-05+0j)\n",
      "(4.4781368534026135e-05+0j)\n",
      "(3.121425762017795e-05+0j)\n",
      "(3.08894163688971e-05+0j)\n",
      "(1.6573039128030194e-05+0j)\n",
      "(1.539579310730578e-05+0j)\n",
      "(1.1881359148110744e-05+0j)\n",
      "(1.1795700905719999e-05+0j)\n",
      "(9.318632661123835e-06+0j)\n",
      "(8.63109410852137e-06+0j)\n",
      "(7.542162936422738e-06+0j)\n",
      "(7.375345471082996e-06+0j)\n",
      "(5.077471660864218e-06+0j)\n",
      "(5.050558506525227e-06+0j)\n",
      "(4.378987323413267e-06+0j)\n",
      "(4.076469549793434e-06+0j)\n",
      "(3.699227556735028e-06+0j)\n",
      "(3.576275576027013e-06+0j)\n",
      "(2.8050520644267244e-06+0j)\n",
      "(2.739348711963987e-06+0j)\n",
      "(2.1636024781994756e-06+0j)\n",
      "(1.989856624214391e-06+0j)\n",
      "(1.8156916297307716e-06+0j)\n",
      "(1.8004277869990736e-06+0j)\n",
      "(3.4956541928444725e-07+0j)\n",
      "(3.550194207054707e-07+0j)\n",
      "(1.2536467767828305e-07+0j)\n",
      "(2.0217047189262572e-07+0j)\n",
      "(3.825215621745653e-08+0j)\n",
      "(4.2771586771762795e-08+0j)\n",
      "(3.2535568743256134e-08+0j)\n",
      "(3.070232148631774e-08+0j)\n",
      "(2.8567038220793192e-08+0j)\n",
      "(2.6457247677103764e-08+0j)\n",
      "(2.415071521165345e-08+0j)\n",
      "(2.2373766611103498e-08+0j)\n",
      "(2.1737874278173493e-08+0j)\n",
      "(1.7249926747872086e-08+0j)\n",
      "(1.70916830981818e-08+0j)\n",
      "(9.073285727528972e-09+0j)\n",
      "count =  80\n"
     ]
    }
   ],
   "source": [
    "nx = 64\n",
    "ny = nx\n",
    "nc = 2\n",
    "# 生成随即组态\n",
    "U = load_or_generate_U(nx, ny, nc, \"./U_data/\")\n",
    "print(\"生成的矩阵形状：\", U.shape)\n",
    "# 确定格点\n",
    "fine_op = operator_para(nx, ny, nc, U=U, if_fine=1)\n",
    "V = np.random.rand(nx, ny, nc*2).view(np.complex128)\n",
    "x0 = np.random.rand(nx, ny, nc*2).view(np.complex128)\n",
    "Vout = apply_mat(V, fine_op)\n",
    "start_time = time.perf_counter()\n",
    "V0 = bicgstab(Vout, x0, op=fine_op, if_info=1, tol=1e-8)\n",
    "end_time = time.perf_counter()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1efb48fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.10586814901034813 seconds\n",
      "搭建多重网格...\n",
      "当前层：  0\n",
      "创造近零空间向量...\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.0085211 -0.00281153j 0.00852946-0.00280454j 0.01178134+0.00116124j\n",
      " 0.01177596+0.0011618j  0.01207764-0.00039351j 0.01209375-0.00039004j\n",
      " 0.00949837+0.0040663j  0.00948635+0.00406617j 0.00887919-0.00251304j\n",
      " 0.00886063-0.00251342j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01213212+0.00145302j 0.01226989+0.00112254j 0.01095512-0.00106126j\n",
      " 0.01078938-0.00062515j 0.00503649-0.00192069j 0.00495375-0.00306787j\n",
      " 0.00916054+0.0010172j  0.00939608+0.0007925j  0.01312427+0.00167938j\n",
      " 0.01420803+0.00222061j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01567684+6.05493905e-04j 0.0160284 +7.95280305e-04j\n",
      " 0.01458809-7.51210792e-03j 0.01430458-7.47982275e-03j\n",
      " 0.01415714+1.88747771e-05j 0.01380758+1.14647168e-04j\n",
      " 0.01662272-1.46655273e-03j 0.01686766-1.16450648e-03j\n",
      " 0.00728736+3.40063385e-03j 0.00753706+3.66418307e-03j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01367255-0.00134373j 0.0135649 -0.00107451j 0.01047272+0.00073388j\n",
      " 0.01102283+0.00053781j 0.01196465-0.00163636j 0.01229303-0.00183688j\n",
      " 0.01219509-0.00045758j 0.01234097-0.00037015j 0.01545269-0.00015123j\n",
      " 0.0151685 +0.00352334j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.00880491+0.00174962j 0.00885278+0.00191008j 0.00920091+0.00288862j\n",
      " 0.00916053+0.00282468j 0.00980775-0.00036034j 0.00994001-0.00060377j\n",
      " 0.01155262-0.00112145j 0.01112754-0.00117855j 0.01305933-0.00220281j\n",
      " 0.01318127-0.00218156j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.0095407 +0.00045275j 0.00952957+0.00033693j 0.01004364+0.00319601j\n",
      " 0.0098769 +0.0031926j  0.01218362-0.00281302j 0.01235479-0.00288491j\n",
      " 0.01517505-0.00198618j 0.01527575-0.00200787j 0.01519367-0.0006542j\n",
      " 0.01539153-0.00081755j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.00991237-0.00046368j 0.00961454-0.00100305j 0.01066408+0.00122876j\n",
      " 0.01110717+0.00105577j 0.01372302+0.00625866j 0.01411088+0.00758834j\n",
      " 0.012215  +0.00064206j 0.01157551+0.00068592j 0.01194277-0.00102155j\n",
      " 0.01236998-0.00058684j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.0151707 +0.00159301j 0.01519939+0.00157538j 0.01251837+0.00208822j\n",
      " 0.0125131 +0.00210125j 0.01254551+0.00122256j 0.01251965+0.00120224j\n",
      " 0.00981929+0.00203976j 0.00977721+0.00203335j 0.00733686+0.00019703j\n",
      " 0.00741356+0.00013382j]\n",
      "近零空间向量创造完毕\n",
      "Buliding map...\n",
      "Buliding map finished\n",
      "生成更粗一层对角元与非对角元...\n",
      "dif =  3.384260391022061e-15\n",
      "当前层：  1\n",
      "创造近零空间向量...\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01058894-6.38322955e-05j 0.01051055-1.90953834e-04j\n",
      " 0.00985945-1.12733984e-03j 0.01028195-3.48382439e-05j\n",
      " 0.0107425 +9.60006428e-04j 0.01331301-1.07221461e-03j\n",
      " 0.00674487+1.98199238e-02j 0.00133843+2.44308701e-02j\n",
      " 0.01017787+9.86212867e-06j 0.01027052+7.28878709e-05j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.01438512+0.00159324j  0.0051663 +0.00111498j  0.00467168-0.00545224j\n",
      "  0.00832947+0.00678156j  0.04188371-0.01991477j -0.01243616-0.08361846j\n",
      "  0.02892406+0.0880132j   0.03784412+0.03604463j  0.00913241+0.01493357j\n",
      "  0.01119162+0.00049129j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01520417-0.00605728j 0.01803134-0.00131025j 0.06373251+0.04980265j\n",
      " 0.01376989-0.00096229j 0.01938309+0.00457204j 0.04826681-0.05808876j\n",
      " 0.0377047 +0.00362451j 0.02878476+0.01879608j 0.00492333-0.01331048j\n",
      " 0.01037218+0.00761175j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.00738638+0.00151078j 0.0088976 +0.00070813j 0.01259962-0.00231819j\n",
      " 0.01120858-0.00023493j 0.00687619-0.0013473j  0.0086976 -0.02005341j\n",
      " 0.01760058-0.00736192j 0.01354278-0.05826071j 0.00968783-0.00449426j\n",
      " 0.01468462+0.0002817j ]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.0058212 +0.00165843j 0.00883583-0.00067162j 0.01449793-0.00253613j\n",
      " 0.01056293+0.00194422j 0.01236897-0.01123612j 0.02549342-0.01626032j\n",
      " 0.03741472-0.00788626j 0.11832729+0.07005345j 0.01450448-0.00061027j\n",
      " 0.00157007-0.00667383j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.00407663-0.00558109j  0.01070804-0.00348784j  0.00209392-0.00048962j\n",
      "  0.00986694+0.00109156j  0.0125003 +0.00306228j  0.01051522-0.01136649j\n",
      "  0.02648204+0.04297229j -0.05980321-0.05299007j  0.01438929-0.00262287j\n",
      "  0.01225198+0.00416696j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.01389926-2.18415051e-03j  0.00809459-3.43252276e-03j\n",
      "  0.01294452-7.58184547e-05j  0.01475624-2.02327785e-05j\n",
      "  0.00985712+5.51404283e-04j -0.01273075+4.00290837e-03j\n",
      "  0.01065104-3.60080127e-02j  0.01778425-8.01692943e-04j\n",
      "  0.01542888-1.21126942e-04j  0.01384675+1.38674089e-02j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.01294573+0.00218965j  0.01021788+0.00158711j  0.01070849+0.00169869j\n",
      "  0.01382841-0.00514078j  0.01333452+0.00095196j  0.00730714-0.00494902j\n",
      "  0.03236462-0.01103685j  0.0170712 +0.00141389j -0.0133749 -0.00017621j\n",
      "  0.01190969-0.00045606j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.00936281+0.00379832j  0.01152046+0.00024803j  0.0157169 -0.00642508j\n",
      "  0.02839309-0.01985106j -0.00058822-0.01558094j  0.07425085+0.04287753j\n",
      "  0.0791978 +0.00262127j  0.0311622 -0.20033065j  0.02527503+0.01899169j\n",
      "  0.01144725+0.00021137j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01006557+0.00144863j 0.00971228-0.00268217j 0.01341009+0.0002362j\n",
      " 0.00998805+0.00275342j 0.00369142+0.02492621j 0.02548821-0.00242636j\n",
      " 0.04527706+0.12443172j 0.01259362+0.04088988j 0.0117821 +0.00159045j\n",
      " 0.01419065-0.00023593j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.00984109+0.00064476j  0.01072346+0.00327784j  0.01351179-0.00084372j\n",
      "  0.01301875-0.00011577j  0.01383367-0.00397211j -0.01180742-0.01496119j\n",
      " -0.01186208-0.05011214j -0.05380756+0.02046341j  0.01171682+0.0010758j\n",
      "  0.00912062+0.00140489j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.01012471-1.98813209e-05j  0.01094644-1.49687888e-03j\n",
      "  0.01122802-2.17450853e-04j  0.0110397 -2.98512294e-04j\n",
      "  0.00532747+1.44059056e-03j  0.00892781-9.60148230e-03j\n",
      "  0.01129959-1.39451993e-02j -0.07430927+3.72958371e-02j\n",
      "  0.00974334+1.48358508e-03j  0.01121487-3.57613092e-04j]\n",
      "近零空间向量创造完毕\n",
      "Buliding map...\n",
      "Buliding map finished\n",
      "生成更粗一层对角元与非对角元...\n",
      "dif =  5.104464679253629e-16\n",
      "当前层：  2\n",
      "创造近零空间向量...\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01044114-2.35612607e-04j 0.01125656+1.18772053e-04j\n",
      " 0.01031887+6.33223860e-04j 0.00966601+8.98119012e-04j\n",
      " 0.01198832+2.23251169e-05j 0.01114281+2.13283836e-04j\n",
      " 0.01122354-4.74998506e-04j 0.01108646+2.25487812e-03j\n",
      " 0.0095941 -2.70504665e-04j 0.01154636-1.23567121e-03j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.04393812+0.00157449j  0.01382597+0.03456824j  0.0186746 +0.03205596j\n",
      "  0.00205431+0.00387604j  0.02900078+0.00252582j  0.05221421+0.00812457j\n",
      "  0.01968799+0.002234j    0.02133478+0.00171711j -0.02618329+0.1798154j\n",
      " -0.04359797-0.03426912j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[-0.0122981 -0.01553285j -0.01794085+0.02149805j  0.02478698+0.01325119j\n",
      " -0.01171309+0.05649991j  0.01540253+0.04127902j  0.04554541-0.02687893j\n",
      "  0.0190593 -0.0037259j   0.03720394-0.02290414j  0.08512147+0.00825454j\n",
      "  0.04167566+0.01660216j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[-0.02027692-0.06176816j  0.01574214-0.01108936j  0.01652469+0.00296498j\n",
      "  0.00663224+0.0028472j   0.05334648-0.0235932j   0.01847753+0.00871797j\n",
      "  0.01253685+0.00434446j  0.00518191-0.01183601j  0.02042721-0.00856817j\n",
      " -0.01199053-0.01827094j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01558155-0.00749173j 0.01483322+0.02392074j 0.00690958+0.00138872j\n",
      " 0.00756343+0.00490865j 0.01682256+0.00172029j 0.0327551 -0.0073645j\n",
      " 0.00832231+0.00055538j 0.01856617-0.01537691j 0.02326307+0.00566407j\n",
      " 0.01372032-0.02280523j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[-0.02171837-0.01009478j  0.02323453-0.02966216j  0.01632431-0.00289751j\n",
      "  0.00812325+0.01033632j  0.03151022+0.00424307j  0.02150007+0.00337957j\n",
      "  0.020328  +0.01029373j -0.00785626+0.01314487j  0.00805375-0.01341279j\n",
      "  0.02621309+0.04002286j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.01839034-0.00532883j  0.00901009-0.00781612j  0.01414782-0.00054761j\n",
      "  0.01115863-0.00484519j  0.0084591 -0.00481819j  0.01223835+0.00154008j\n",
      "  0.01366568+0.00635083j -0.00931251+0.00036587j  0.02417715-0.0222991j\n",
      " -0.02363846-0.00690568j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.00829196+0.0031622j  0.01172846+0.00773379j 0.01377762-0.01523579j\n",
      " 0.00530141+0.00874241j 0.01589016-0.00639406j 0.0070374 +0.00132342j\n",
      " 0.01063892+0.01067033j 0.02554222+0.00119274j 0.00669574+0.02800666j\n",
      " 0.02157364-0.00940008j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01710403-0.00605168j 0.01391224-0.00357542j 0.0103864 -0.00330281j\n",
      " 0.00186323-0.02039962j 0.01375633-0.00230182j 0.0191143 +0.0037272j\n",
      " 0.01194082+0.00011798j 0.01880501+0.00345522j 0.00688036+0.00543949j\n",
      " 0.01475727-0.0044072j ]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.01926723+0.00783343j  0.00939412+0.00468378j  0.00878626+0.00189337j\n",
      "  0.0129657 +0.00094708j  0.01170173+0.00234493j  0.01206459-0.00178718j\n",
      "  0.01118974-0.00035412j  0.00531362+0.00445259j  0.01662832+0.00674303j\n",
      " -0.00057441+0.01001711j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[0.01407875-0.00072387j 0.02075745+0.01021532j 0.01006523+0.00047387j\n",
      " 0.01055796-0.0023829j  0.01080785-0.00742629j 0.01381952-0.00259396j\n",
      " 0.01601216-0.00212549j 0.0141249 +0.00310823j 0.00360108+0.00562464j\n",
      " 0.01686145+0.00146148j]\n",
      "(apply_mat(P_null_vec_coarse[i, :, :, :], coarse_op)/P_null_vec_coarse[i, :, :, :]).flatten()[:10]:[ 0.01339631+0.00758621j  0.01385938-0.00216445j  0.03130975-0.00453159j\n",
      "  0.05143906+0.01047972j  0.03100858+0.0086841j   0.00587547+0.00067427j\n",
      "  0.01613781+0.00824423j -0.00370826-0.0139789j   0.01722265+0.00364697j\n",
      "  0.01203138+0.00622448j]\n",
      "近零空间向量创造完毕\n",
      "Buliding map...\n",
      "Buliding map finished\n",
      "生成更粗一层对角元与非对角元...\n",
      "dif =  1.6655261965465192e-16\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "my_mg = mg(fine_op, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e58ccaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " level =  0 (133.30605917728704+0j)\n",
      " level =  0 (15.15302023937057+0j)\n",
      "0_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):7.452661051372012\n",
      "  level =  1 (3.392643175288037+0j)\n",
      "  level =  1 (1.5269365641634898+0j)\n",
      "   level =  2 (0.5039841400275876+0j)\n",
      "   level =  2 (0.2828357466958365+0j)\n",
      "    level 3   iter 4\n",
      "   level =  2 (0.16560710454315342+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.22424165971838514+0j)\n",
      "   level 2   iter 2\n",
      "  level =  1 (0.7352534620802091+0j)\n",
      "  level =  1 RelRes (0.21671995081468765+0j)\n",
      "  level 1   iter 2\n",
      "0_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):7.308224679829183\n",
      " level =  0 (2.2958555801921143+0j)\n",
      "1_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.2554977237225127\n",
      "  level =  1 (0.5210598323897258+0j)\n",
      "  level =  1 (0.40514549596903715+0j)\n",
      "   level =  2 (0.1713850610545764+0j)\n",
      "   level =  2 (0.1090372369993133+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0698604175683893+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.04208611135873599+0j)\n",
      "   level =  2 RelRes (0.24556464314782928+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.4383979317082691+0j)\n",
      "   level =  2 (0.2022315443703904+0j)\n",
      "   level =  2 (0.09351816629737043+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.03840797138260224+0j)\n",
      "   level =  2 RelRes (0.18992077374564972+0j)\n",
      "   level 2   iter 2\n",
      "  level =  1 (0.45260162000957627+0j)\n",
      "   level =  2 (0.07568576203916295+0j)\n",
      "   level =  2 (0.046398543150130596+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.030651192472009547+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.023469258784107036+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.20414201733657997+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.4216764710521588+0j)\n",
      "   level =  2 (0.04974562689915828+0j)\n",
      "   level =  2 (0.03185438721667248+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.017611291288179974+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.011959927081593448+0j)\n",
      "   level =  2 RelRes (0.24042167778562695+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.20589301396413234+0j)\n",
      "   level =  2 (0.03483084066986059+0j)\n",
      "   level =  2 (0.02355785902591604+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.013610918612911532+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.24524436872753963+0j)\n",
      "   level 2   iter 2\n",
      "  level =  1 RelRes (0.15270269634754413+0j)\n",
      "  level 1   iter 5\n",
      "1_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.2727017137373766\n",
      " level =  0 (0.42566887124965896+0j)\n",
      "2_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.2549276933597472\n",
      "  level =  1 (0.21741804651688076+0j)\n",
      "  level =  1 (0.09181382735009624+0j)\n",
      "   level =  2 (0.034698659360089805+0j)\n",
      "   level =  2 (0.022810519666340536+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.01303608647691967+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.24155859968516613+0j)\n",
      "   level 2   iter 2\n",
      "  level =  1 (0.08392218495803697+0j)\n",
      "   level =  2 (0.019313958479112384+0j)\n",
      "   level =  2 (0.013999816547930028+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.008429811979633273+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.005607791871959017+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21777663744973297+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 RelRes (0.244433430300551+0j)\n",
      "  level 1   iter 2\n",
      "2_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.3245435733350111\n",
      " level =  0 (0.12993870890660053+0j)\n",
      "3_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.08481489777413861\n",
      "  level =  1 (0.07190579850636482+0j)\n",
      "  level =  1 (0.04548158764991567+0j)\n",
      "   level =  2 (0.01722650606455609+0j)\n",
      "   level =  2 (0.011747707027133918+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.006860966813008007+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.004193243871875706+0j)\n",
      "   level =  2 RelRes (0.24341812879301142+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.04725965418744501+0j)\n",
      "   level =  2 (0.011219189055797612+0j)\n",
      "   level =  2 (0.007824588675288072+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.004389346276749202+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.00365802013019054+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2087834690222637+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.016043825556525657+0j)\n",
      "  level =  1 RelRes (0.2231228341773511+0j)\n",
      "  level 1   iter 3\n",
      "3_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.12519094978877607\n",
      " level =  0 (0.04448855108898052+0j)\n",
      "4_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.03140561424532649\n",
      "  level =  1 (0.02581583329346127+0j)\n",
      "  level =  1 (0.018291325343410315+0j)\n",
      "   level =  2 (0.008703807756080605+0j)\n",
      "   level =  2 (0.006189453366713924+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.003801412191591171+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.002392384804966846+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.19057125063252897+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.037276371671072735+0j)\n",
      "   level =  2 (0.005846576522330857+0j)\n",
      "   level =  2 (0.004458403801571719+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.002066984896265544+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.0015090105266105758+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2022557553446254+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.010140000670892876+0j)\n",
      "   level =  2 (0.0034698605984728355+0j)\n",
      "   level =  2 (0.002681078342767451+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.0014141064894296763+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.0009906877466171087+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.22432895848009732+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.035253100157788694+0j)\n",
      "   level =  2 (0.0030390850234137024+0j)\n",
      "   level =  2 (0.0022044672425866473+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0009952287312556855+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0006405551071413278+0j)\n",
      "   level =  2 RelRes (0.21077235490496865+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.012224808874120158+0j)\n",
      "   level =  2 (0.0023785753460655694+0j)\n",
      "   level =  2 (0.002077113811546372+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0009920380475859753+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.00059107686100696+0j)\n",
      "   level =  2 RelRes (0.24850037312657236+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 RelRes (0.19674939180163858+0j)\n",
      "  level 1   iter 5\n",
      "4_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.05134510356188702\n",
      " level =  0 (0.018759236552076414+0j)\n",
      "5_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.013874899130390597\n",
      "  level =  1 (0.010767949652726929+0j)\n",
      "  level =  1 (0.006899131591881777+0j)\n",
      "   level =  2 (0.002846371931607974+0j)\n",
      "   level =  2 (0.0020313168974547447+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0011946250309086152+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0006636400826000747+0j)\n",
      "   level =  2 RelRes (0.23315297457460904+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.003646604831841942+0j)\n",
      "   level =  2 (0.001352552372895675+0j)\n",
      "   level =  2 (0.0010459210966875059+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.0005464598994249375+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.00042111256551612976+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.23190287258953812+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0019410815598989908+0j)\n",
      "  level =  1 RelRes (0.18026473214493735+0j)\n",
      "  level 1   iter 3\n",
      "5_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.02226411491880275\n",
      " level =  0 (0.009173376368794743+0j)\n",
      "6_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.00705445047476627\n",
      "  level =  1 (0.0053413795490757756+0j)\n",
      "  level =  1 (0.004157318835126835+0j)\n",
      "   level =  2 (0.0017522420086348856+0j)\n",
      "   level =  2 (0.0012452887877715388+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0006891860999529369+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0004153274049824732+0j)\n",
      "   level =  2 RelRes (0.23702628000914164+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.003126273217605166+0j)\n",
      "   level =  2 (0.0009432906409125785+0j)\n",
      "   level =  2 (0.0007567589432378065+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0003564931518185047+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.00025191684111770243+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2196218671463585+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0012809942631714021+0j)\n",
      "  level =  1 RelRes (0.23982460924220483+0j)\n",
      "  level 1   iter 3\n",
      "6_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.012206074986575737\n",
      " level =  0 (0.004840236061671863+0j)\n",
      "7_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0037656922180436753\n",
      "  level =  1 (0.002812917500132199+0j)\n",
      "  level =  1 (0.002424470798349499+0j)\n",
      "   level =  2 (0.0010381002857935589+0j)\n",
      "   level =  2 (0.0007654829416243761+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.00040341285855433913+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.00024832096913412506+0j)\n",
      "   level =  2 RelRes (0.23920710988370467+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.002045495679403575+0j)\n",
      "   level =  2 (0.0006190583565056579+0j)\n",
      "   level =  2 (0.0004836605152344496+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0002417160910196623+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.00016345297097965426+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21472112171647473+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.001074440724890366+0j)\n",
      "   level =  2 (0.0003829526263819598+0j)\n",
      "   level =  2 (0.000299969053623099+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0001632426941366009+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (0.00010287240518672238+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2273409227934107+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0008531929031681789+0j)\n",
      "   level =  2 (0.0002773389413908779+0j)\n",
      "   level =  2 (0.0002125431549383493+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.0001194165369801911+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (7.495411829729769e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2219897179047897+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0019083670927461643+0j)\n",
      "   level =  2 (0.0002673113637028425+0j)\n",
      "   level =  2 (0.0002186134805683735+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (9.263820259834374e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.1033519023122986e-05+0j)\n",
      "   level =  2 RelRes (0.22832369779449813+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0017145575963229756+0j)\n",
      "   level =  2 (0.00025397894735699805+0j)\n",
      "   level =  2 (0.0002226571046838745+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.00011279536308558247+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.427076022358868e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21021411379972177+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 RelRes (0.22409076575549133+0j)\n",
      "  level 1   iter 6\n",
      "7_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0071093683150723576\n",
      " level =  0 (0.0027571297953596554+0j)\n",
      "8_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0021412384868918196\n",
      "  level =  1 (0.0015932422619639815+0j)\n",
      "  level =  1 (0.001172527113835592+0j)\n",
      "   level =  2 (0.00046135200438278303+0j)\n",
      "   level =  2 (0.0003428093694547251+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.00017887994924087474+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (9.520372424412374e-05+0j)\n",
      "   level =  2 RelRes (0.20635810257612616+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.00042317104891345913+0j)\n",
      "   level =  2 (0.0001724547486363483+0j)\n",
      "   level =  2 (0.00014150164334448005+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (7.591531676076521e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (5.182469700142465e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.23498415558228436+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0003019814610260741+0j)\n",
      "  level =  1 RelRes (0.18953894723695258+0j)\n",
      "  level 1   iter 3\n",
      "8_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0035980474245381902\n",
      " level =  0 (0.0015757047300005737+0j)\n",
      "9_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0012169749907846136\n",
      "  level =  1 (0.0008880518521696687+0j)\n",
      "  level =  1 (0.0007561839700090251+0j)\n",
      "   level =  2 (0.00030072136698276866+0j)\n",
      "   level =  2 (0.00022670342501724465+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (0.00010844272080011585+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.403620634849562e-05+0j)\n",
      "   level =  2 RelRes (0.212941990091994+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0003625623403114714+0j)\n",
      "   level =  2 (0.00013664206481642878+0j)\n",
      "   level =  2 (0.0001065805297919208+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (5.899652961448642e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (3.787047179868155e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.22033363356074462+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0001918250889190767+0j)\n",
      "  level =  1 RelRes (0.2160066312011105+0j)\n",
      "  level 1   iter 3\n",
      "9_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.002185573244972139\n",
      " level =  0 (0.0009091070489450723+0j)\n",
      "10_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0007096584986619207\n",
      "  level =  1 (0.0005198795066966086+0j)\n",
      "  level =  1 (0.0004651688917644385+0j)\n",
      "   level =  2 (0.00019230836143761763+0j)\n",
      "   level =  2 (0.0001521580229807592+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.949852920483099e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.1575441583101886e-05+0j)\n",
      "   level =  2 RelRes (0.216191543998925+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.00027871913796204275+0j)\n",
      "   level =  2 (9.69173067125299e-05+0j)\n",
      "   level =  2 (7.283075179783646e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.315807146766094e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.6902336011365885e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21796923906707846+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.00017745233451860266+0j)\n",
      "   level =  2 (5.5061150785877816e-05+0j)\n",
      "   level =  2 (4.5168278798148764e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.468236005316099e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.4987921356648596e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.24182464110784338+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.00011756294413049297+0j)\n",
      "  level =  1 RelRes (0.2261349843880274+0j)\n",
      "  level 1   iter 4\n",
      "10_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0013427721581505954\n",
      " level =  0 (0.000553852109007821+0j)\n",
      "11_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0004285677665994358\n",
      "  level =  1 (0.0003127927625370123+0j)\n",
      "  level =  1 (0.0002756182502828167+0j)\n",
      "   level =  2 (0.00011381276431457204+0j)\n",
      "   level =  2 (9.076679041439644e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.132768756028425e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.4073865331052976e-05+0j)\n",
      "   level =  2 RelRes (0.2115216643408658+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.00014804575615825024+0j)\n",
      "   level =  2 (5.6686856826000205e-05+0j)\n",
      "   level =  2 (4.24931474368338e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.5488129888766145e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.5366859682754134e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21451635473014738+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (7.794162386854281e-05+0j)\n",
      "  level =  1 RelRes (0.24917975478834836+0j)\n",
      "  level 1   iter 3\n",
      "11_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.000797980999288602\n",
      " level =  0 (0.0003388524945926659+0j)\n",
      "12_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0002598989553076967\n",
      "  level =  1 (0.00018905490632358107+0j)\n",
      "  level =  1 (0.00018013150873482674+0j)\n",
      "   level =  2 (7.521022535866612e-05+0j)\n",
      "   level =  2 (6.171929442059405e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.840791637012763e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.665161255814399e-05+0j)\n",
      "   level =  2 RelRes (0.22140091295744674+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (0.0001171662030473311+0j)\n",
      "   level =  2 (4.158905361277915e-05+0j)\n",
      "   level =  2 (2.918959298770902e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.8601911022910024e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.1265657971678084e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.20876596133759334+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (5.9944880801125884e-05+0j)\n",
      "   level =  2 (2.1774295740407202e-05+0j)\n",
      "   level =  2 (1.7807539520688597e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.0612810213329605e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (6.129277546048914e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (4.436925369526988e-06+0j)\n",
      "   level =  2 RelRes (0.20376894951845698+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (5.7350829983594214e-05+0j)\n",
      "   level =  2 (1.5833935728243654e-05+0j)\n",
      "   level =  2 (1.2659728799253835e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.29430752955717e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.9338294774606974e-06+0j)\n",
      "   level =  2 RelRes (0.24844293579162136+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 RelRes (0.24346788043624318+0j)\n",
      "  level 1   iter 4\n",
      "12_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.000512247900987572\n",
      " level =  0 (0.0002103257260435793+0j)\n",
      "13_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.0001619313331302524\n",
      "  level =  1 (0.000118443298904716+0j)\n",
      "  level =  1 (0.0001034572676477564+0j)\n",
      "   level =  2 (4.4051237440046915e-05+0j)\n",
      "   level =  2 (3.512917603477592e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.6709897949069236e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.24964390631861594+0j)\n",
      "   level 2   iter 2\n",
      "  level =  1 (5.0158618343157794e-05+0j)\n",
      "   level =  2 (2.1150766043144973e-05+0j)\n",
      "   level =  2 (1.657967657473761e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.0427286770647509e-05+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (5.582363102480641e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.22288487994421693+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (2.711224942124137e-05+0j)\n",
      "  level =  1 RelRes (0.22890488252148686+0j)\n",
      "  level 1   iter 3\n",
      "13_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.00030582369185472275\n",
      " level =  0 (0.0001316398090264196+0j)\n",
      "14_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.00010006833115713714\n",
      "  level =  1 (7.250666253758367e-05+0j)\n",
      "  level =  1 (6.930487546505786e-05+0j)\n",
      "   level =  2 (2.9853200376856336e-05+0j)\n",
      "   level =  2 (2.4921209068343872e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.2063131021552102e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.574274339361748e-06+0j)\n",
      "   level =  2 RelRes (0.22022008549738095+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (4.5559248404166006e-05+0j)\n",
      "   level =  2 (1.602717678427588e-05+0j)\n",
      "   level =  2 (1.0989252555587006e-05+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (7.5235425429529955e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.3220496124149185e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.20882705258793005+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (2.274590034123219e-05+0j)\n",
      "   level =  2 (8.13667215040285e-06+0j)\n",
      "   level =  2 (6.720567576126186e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.161097416278464e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.349208128930335e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.747860021697877e-06+0j)\n",
      "   level =  2 RelRes (0.21481263953978283+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (2.756695465465314e-05+0j)\n",
      "   level =  2 (6.338765415739345e-06+0j)\n",
      "   level =  2 (5.055834883765658e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.4888220807631774e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.5473756512199792e-06+0j)\n",
      "   level =  2 RelRes (0.24411309612086274+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (5.226291835693775e-05+0j)\n",
      "   level =  2 (7.639499864639577e-06+0j)\n",
      "   level =  2 (6.6579306377751574e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.3959777851626193e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.8474932909262796e-06+0j)\n",
      "   level =  2 RelRes (0.24183432471510913+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (3.144651106771549e-05+0j)\n",
      "   level =  2 (4.862437768517419e-06+0j)\n",
      "   level =  2 (3.75885294312446e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.4036908252987397e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.3568675700322626e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2205213875492294+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 RelRes (0.16697388961884552+0j)\n",
      "  level 1   iter 6\n",
      "14_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.00020708671812268237\n",
      " level =  0 (8.387615971028557e-05+0j)\n",
      "15_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):6.444625604898082e-05\n",
      "  level =  1 (4.741460690268127e-05+0j)\n",
      "  level =  1 (3.8184813855692554e-05+0j)\n",
      "   level =  2 (1.6574029986981276e-05+0j)\n",
      "   level =  2 (1.2738335406495914e-05+0j)\n",
      "    level 3   iter 4\n",
      "   level =  2 (7.402230684212374e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (3.0724563122812735e-06+0j)\n",
      "   level =  2 RelRes (0.18537774546653138+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.561183131945879e-05+0j)\n",
      "   level =  2 (6.1546395416761395e-06+0j)\n",
      "   level =  2 (4.733589508772294e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.075246326010021e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.714277300248967e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.22586032600372666+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.0355309060071062e-05+0j)\n",
      "  level =  1 RelRes (0.21839913344268336+0j)\n",
      "  level 1   iter 3\n",
      "15_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):0.00011916238772963583\n",
      " level =  0 (5.244534271460712e-05+0j)\n",
      "16_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):3.992457836151504e-05\n",
      "  level =  1 (2.9052860061513147e-05+0j)\n",
      "  level =  1 (2.6462623417430226e-05+0j)\n",
      "   level =  2 (1.15032440342033e-05+0j)\n",
      "   level =  2 (9.075795798179236e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.81661656197967e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.363834162374533e-06+0j)\n",
      "   level =  2 RelRes (0.20549282927024762+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.428132247063406e-05+0j)\n",
      "   level =  2 (5.172131201162889e-06+0j)\n",
      "   level =  2 (3.631662947420377e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.5904162392947314e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.4199457138894196e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21522590872018524+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (6.880909467791938e-06+0j)\n",
      "  level =  1 RelRes (0.23684103572670986+0j)\n",
      "  level 1   iter 3\n",
      "16_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):7.840383636537976e-05\n",
      " level =  0 (3.2731052747382283e-05+0j)\n",
      "17_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):2.5154105836309656e-05\n",
      "  level =  1 (1.8437408902017965e-05+0j)\n",
      "  level =  1 (1.7211519263909782e-05+0j)\n",
      "   level =  2 (7.752987062490167e-06+0j)\n",
      "   level =  2 (6.246473273533247e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.431188409230233e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.670983590110019e-06+0j)\n",
      "   level =  2 RelRes (0.215527715529725+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.0792810943283405e-05+0j)\n",
      "   level =  2 (3.7533023168343246e-06+0j)\n",
      "   level =  2 (2.5968598799221075e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.946702934317288e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.042256551232799e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21869602490783477+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (4.987403340801274e-06+0j)\n",
      "   level =  2 (1.8477663600271602e-06+0j)\n",
      "   level =  2 (1.565727055858226e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.066444566227376e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (5.675704115771354e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (4.265546187001358e-07+0j)\n",
      "   level =  2 RelRes (0.23084878474238807+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (2.836239947744333e-06+0j)\n",
      "  level =  1 RelRes (0.15383072333086392+0j)\n",
      "  level 1   iter 4\n",
      "17_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):5.178697478958216e-05\n",
      " level =  0 (2.099858719821761e-05+0j)\n",
      "18_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.619564800185107e-05\n",
      "  level =  1 (1.1950399228509529e-05+0j)\n",
      "  level =  1 (1.0598919378166756e-05+0j)\n",
      "   level =  2 (4.93451686298425e-06+0j)\n",
      "   level =  2 (3.8107788625519802e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.175162161650068e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (9.73732115708076e-07+0j)\n",
      "   level =  2 RelRes (0.19733079098633205+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (6.041264296938083e-06+0j)\n",
      "   level =  2 (2.180705839381991e-06+0j)\n",
      "   level =  2 (1.5722181221052782e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.1574481185871298e-06+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (5.879287184181086e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2187889346122478+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (3.3477765914452325e-06+0j)\n",
      "   level =  2 (1.1367795626384433e-06+0j)\n",
      "   level =  2 (9.90012409124727e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (5.85089686479933e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.388402861317124e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.6213645211159626e-07+0j)\n",
      "   level =  2 RelRes (0.23059567635363065+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (2.30578367656525e-06+0j)\n",
      "  level =  1 RelRes (0.19294616292520553+0j)\n",
      "  level 1   iter 4\n",
      "18_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):3.298022255069368e-05\n",
      " level =  0 (1.3415079936568915e-05+0j)\n",
      "19_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.037492222742005e-05\n",
      "  level =  1 (7.681679064159155e-06+0j)\n",
      "  level =  1 (6.881663923544069e-06+0j)\n",
      "   level =  2 (3.252681232059005e-06+0j)\n",
      "   level =  2 (2.4351992399212554e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.4448887183510628e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.211069388937697e-07+0j)\n",
      "   level =  2 RelRes (0.19095229276451353+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (3.996946871472372e-06+0j)\n",
      "   level =  2 (1.4202695030834217e-06+0j)\n",
      "   level =  2 (1.0063232514167402e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (7.533049087930988e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.7557685722041964e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2135038995203716+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (2.152664455409634e-06+0j)\n",
      "   level =  2 (7.313407727491317e-07+0j)\n",
      "   level =  2 (6.304631571104006e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (3.747721630010641e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.1632405922401483e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.676287907564423e-07+0j)\n",
      "   level =  2 RelRes (0.2292075008020142+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (1.8211390679299983e-06+0j)\n",
      "  level =  1 RelRes (0.23707565139332493+0j)\n",
      "  level 1   iter 4\n",
      "19_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):2.1355861400124625e-05\n",
      " level =  0 (8.56027709778779e-06+0j)\n",
      "20_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):6.654756949270202e-06\n",
      "  level =  1 (4.958660904893995e-06+0j)\n",
      "  level =  1 (4.455685595082726e-06+0j)\n",
      "   level =  2 (2.1395587438782094e-06+0j)\n",
      "   level =  2 (1.5717978280130817e-06+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (9.692218858023488e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.0165786198550884e-07+0j)\n",
      "   level =  2 RelRes (0.18772929845219172+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (2.6379658316204286e-06+0j)\n",
      "   level =  2 (9.290512423269873e-07+0j)\n",
      "   level =  2 (6.542140417960398e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.973242386055081e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.43714972001832e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21200034895569753+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.3652391438945037e-06+0j)\n",
      "   level =  2 (4.753701298159301e-07+0j)\n",
      "   level =  2 (4.072094040828846e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.465933507715245e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.4065866447132657e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.0948788717925768e-07+0j)\n",
      "   level =  2 RelRes (0.23032134396339315+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (5.861576873751576e-06+0j)\n",
      "   level =  2 (9.234811214777037e-07+0j)\n",
      "   level =  2 (4.6338465552552397e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.879556120563372e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21860709117007446+0j)\n",
      "   level 2   iter 2\n",
      "  level =  1 (2.1294006942330523e-06+0j)\n",
      "   level =  2 (3.4814076816977185e-07+0j)\n",
      "   level =  2 (2.903898270664905e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.5119354788337166e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (9.131707902659121e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.2359716252301395+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 RelRes (0.21395636404886706+0j)\n",
      "  level 1   iter 5\n",
      "20_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.4150862626271194e-05\n",
      " level =  0 (5.60879515383295e-06+0j)\n",
      "21_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):4.341745126804887e-06\n",
      "  level =  1 (3.2526714066300587e-06+0j)\n",
      "  level =  1 (2.767064475530674e-06+0j)\n",
      "   level =  2 (1.342602681967719e-06+0j)\n",
      "   level =  2 (9.464834692448964e-07+0j)\n",
      "    level 3   iter 4\n",
      "   level =  2 (7.061849385536844e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.334552506768447e-07+0j)\n",
      "   level =  2 RelRes (0.17388260414815543+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.3590177330963761e-06+0j)\n",
      "   level =  2 (5.216908798910779e-07+0j)\n",
      "   level =  2 (3.928531961525925e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.812106776444739e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.3678119028559742e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.22366358467656913+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (7.904280884246262e-07+0j)\n",
      "  level =  1 RelRes (0.24300889626092048+0j)\n",
      "  level 1   iter 3\n",
      "21_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):8.634773669016653e-06\n",
      " level =  0 (3.5456155722662273e-06+0j)\n",
      "22_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):2.741916080878033e-06\n",
      "  level =  1 (2.0446819547559228e-06+0j)\n",
      "  level =  1 (1.932323085724808e-06+0j)\n",
      "   level =  2 (9.193110310855511e-07+0j)\n",
      "   level =  2 (6.780568401696511e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.6853288494837875e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.830389461982015e-07+0j)\n",
      "   level =  2 RelRes (0.1991044815181467+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.267120332628189e-06+0j)\n",
      "   level =  2 (4.3360070759066274e-07+0j)\n",
      "   level =  2 (2.934702056505195e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.320281229759872e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.1606372192655835e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.2141729566636261+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (5.395181764677477e-07+0j)\n",
      "   level =  2 (2.0690011309843838e-07+0j)\n",
      "   level =  2 (1.774252666018163e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.2156874781069108e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (6.504422143271213e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (5.0289952456853116e-08+0j)\n",
      "   level =  2 RelRes (0.2430639196070729+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (3.426980375575908e-07+0j)\n",
      "  level =  1 RelRes (0.16760456889663278+0j)\n",
      "  level 1   iter 4\n",
      "22_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):5.849840505118508e-06\n",
      " level =  0 (2.2718617473335748e-06+0j)\n",
      "23_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.778644694498787e-06\n",
      "  level =  1 (1.3430682562409535e-06+0j)\n",
      "  level =  1 (1.1927306566253043e-06+0j)\n",
      "   level =  2 (5.965508388631652e-07+0j)\n",
      "   level =  2 (4.3074030223537186e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.0278233953137244e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.1018473502128556e-07+0j)\n",
      "   level =  2 RelRes (0.18470300910357007+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (7.283438961176684e-07+0j)\n",
      "   level =  2 (2.5045337868202754e-07+0j)\n",
      "   level =  2 (1.8139632031316983e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.4373631016021572e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (6.79914244801015e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.22467429784838558+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (3.699042097499498e-07+0j)\n",
      "   level =  2 (1.288555425613343e-07+0j)\n",
      "   level =  2 (1.1317623990399092e-07+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (6.922433072268461e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (4.017780463777057e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (3.1375871745817716e-08+0j)\n",
      "   level =  2 RelRes (0.2434964854607091+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (2.484926442667729e-07+0j)\n",
      "  level =  1 RelRes (0.18501862664989682+0j)\n",
      "  level 1   iter 4\n",
      "23_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):3.76633794784893e-06\n",
      " level =  0 (1.4671157517313998e-06+0j)\n",
      "24_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.1488253974693473e-06\n",
      "  level =  1 (8.685585646778226e-07+0j)\n",
      "  level =  1 (7.844032053057574e-07+0j)\n",
      "   level =  2 (3.904621569933703e-07+0j)\n",
      "   level =  2 (2.751656090983867e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.9618170557289914e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.984215142282346e-08+0j)\n",
      "   level =  2 RelRes (0.17887047482557786+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (4.829270495388718e-07+0j)\n",
      "   level =  2 (1.6833490020848576e-07+0j)\n",
      "   level =  2 (1.191168030511824e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (9.15240190313878e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.455871614313592e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21489018863863327+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (2.292340735501943e-07+0j)\n",
      "   level =  2 (8.455516458571989e-08+0j)\n",
      "   level =  2 (7.395430120157983e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (4.704619713387731e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.60815515651894e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.0240409005272012e-08+0j)\n",
      "   level =  2 RelRes (0.2393751949326856+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (1.3837345606211852e-07+0j)\n",
      "  level =  1 RelRes (0.15931390431161754+0j)\n",
      "  level 1   iter 4\n",
      "24_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):2.4465718740434187e-06\n",
      " level =  0 (9.494404352546444e-07+0j)\n",
      "25_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):7.444416102005362e-07\n",
      "  level =  1 (5.640812572757377e-07+0j)\n",
      "  level =  1 (5.045815228964425e-07+0j)\n",
      "   level =  2 (2.5355762435446255e-07+0j)\n",
      "   level =  2 (1.7878086928337275e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.2693919855369088e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.503851291549746e-08+0j)\n",
      "   level =  2 RelRes (0.1776263404824127+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (3.1049662345247395e-07+0j)\n",
      "   level =  2 (1.0682958041398162e-07+0j)\n",
      "   level =  2 (7.653563342993476e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (5.960228944597707e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.8556869827326825e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21817163337226056+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.5339587510323842e-07+0j)\n",
      "   level =  2 (5.441229846654717e-08+0j)\n",
      "   level =  2 (4.7895810435854686e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (3.009202895361924e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.6881148264715665e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.3062603713362622e-08+0j)\n",
      "   level =  2 RelRes (0.2400671186752669+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (8.964189520833861e-08+0j)\n",
      "  level =  1 RelRes (0.1589166348856709+0j)\n",
      "  level 1   iter 4\n",
      "25_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.5864462072179784e-06\n",
      " level =  0 (6.144737694387155e-07+0j)\n",
      "26_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):4.824588300177434e-07\n",
      "  level =  1 (3.661725798553164e-07+0j)\n",
      "  level =  1 (3.2787500926003424e-07+0j)\n",
      "   level =  2 (1.6458781269598212e-07+0j)\n",
      "   level =  2 (1.1530113495489447e-07+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (8.220958077508943e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.8960442130127635e-08+0j)\n",
      "   level =  2 RelRes (0.17595739110782052+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (2.017615611077803e-07+0j)\n",
      "   level =  2 (6.962433761653184e-08+0j)\n",
      "   level =  2 (4.9839859171371534e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.8363072958103776e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.8523531341856006e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 RelRes (0.21717828104190956+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (9.824684164507652e-08+0j)\n",
      "   level =  2 (3.536044885330465e-08+0j)\n",
      "   level =  2 (3.1183741161473626e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.9909064955509284e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.0950271089194618e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (8.438509360079998e-09+0j)\n",
      "   level =  2 RelRes (0.2386425974140701+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (5.7247739848556426e-08+0j)\n",
      "  level =  1 RelRes (0.15634087039279781+0j)\n",
      "  level 1   iter 4\n",
      "26_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.0306329533505536e-06\n",
      " level =  0 (3.977937665267741e-07+0j)\n",
      "27_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):3.1281853901585425e-07\n",
      "  level =  1 (2.37832480406598e-07+0j)\n",
      "  level =  1 (2.1218440505894712e-07+0j)\n",
      "   level =  2 (1.0668120284004424e-07+0j)\n",
      "   level =  2 (7.465689871038111e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (5.3114202685255583e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.870817114093057e-08+0j)\n",
      "   level =  2 RelRes (0.17536520626769875+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.3031342178481197e-07+0j)\n",
      "   level =  2 (4.4880570478011085e-08+0j)\n",
      "   level =  2 (3.229381874982222e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.4786106401796205e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.1960579335978003e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21948328326392172+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (6.392368973346484e-08+0j)\n",
      "   level =  2 (2.2897112512489796e-08+0j)\n",
      "   level =  2 (2.026774674554555e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.2923159378293342e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (7.0868603479308716e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (5.4497032926329265e-09+0j)\n",
      "   level =  2 RelRes (0.23800832046662004+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (3.699941687645811e-08+0j)\n",
      "  level =  1 RelRes (0.15556923433335923+0j)\n",
      "  level 1   iter 4\n",
      "27_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):6.688475872610361e-07\n",
      " level =  0 (2.5755289209367706e-07+0j)\n",
      "28_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):2.0278386254560749e-07\n",
      "  level =  1 (1.5439062321025232e-07+0j)\n",
      "  level =  1 (1.375146637697353e-07+0j)\n",
      "   level =  2 (6.918009870574806e-08+0j)\n",
      "   level =  2 (4.8294084634510755e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.4329200007282717e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.2093008411738367e-08+0j)\n",
      "   level =  2 RelRes (0.1748047290764212+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (8.432257707779555e-08+0j)\n",
      "   level =  2 (2.904643065156734e-08+0j)\n",
      "   level =  2 (2.095344444094531e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.599135890792505e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (7.735605683487788e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21966895272456857+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (4.1426000270094345e-08+0j)\n",
      "   level =  2 (1.483885873357493e-08+0j)\n",
      "   level =  2 (1.316496387148582e-08+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (8.403610846662222e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (4.590710201001219e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.5250886418439283e-09+0j)\n",
      "   level =  2 RelRes (0.23755793522502763+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (2.394388423113829e-08+0j)\n",
      "  level =  1 RelRes (0.15508638888341694+0j)\n",
      "  level 1   iter 4\n",
      "28_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):4.3399142242758303e-07\n",
      " level =  0 (1.667335117101742e-07+0j)\n",
      "29_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.314235025236456e-07\n",
      "  level =  1 (1.0018824008908466e-07+0j)\n",
      "  level =  1 (8.913353603014474e-08+0j)\n",
      "   level =  2 (4.487258012397836e-08+0j)\n",
      "   level =  2 (3.1267810104126354e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.2220882086861988e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (7.828884877110552e-09+0j)\n",
      "   level =  2 RelRes (0.17446923835179842+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (5.460818780659832e-08+0j)\n",
      "   level =  2 (1.8811601699250674e-08+0j)\n",
      "   level =  2 (1.3595921307668903e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.0328104011602525e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (5.007670657816294e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21980731980899787+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (2.6847485336354313e-08+0j)\n",
      "   level =  2 (9.618303501522998e-09+0j)\n",
      "   level =  2 (8.548417503995179e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (5.458057876886466e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.974794802541108e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.282111266224254e-09+0j)\n",
      "   level =  2 RelRes (0.23726754576447873+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (1.5515457498844385e-08+0j)\n",
      "  level =  1 RelRes (0.1548630606251638+0j)\n",
      "  level 1   iter 4\n",
      "29_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):2.815288942084342e-07\n",
      " level =  0 (1.0793712327688017e-07+0j)\n",
      "30_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):8.515684788507387e-08\n",
      "  level =  1 (6.499047948827908e-08+0j)\n",
      "  level =  1 (5.7784471712199435e-08+0j)\n",
      "   level =  2 (2.9109340347986538e-08+0j)\n",
      "   level =  2 (2.025240421782043e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.4401824192095911e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (5.0713474545857035e-09+0j)\n",
      "   level =  2 RelRes (0.17421718918946522+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (3.539581626630434e-08+0j)\n",
      "   level =  2 (1.2195838463367175e-08+0j)\n",
      "   level =  2 (8.823952388754172e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.6749976744126214e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.2446210543563325e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21980754385132878+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.7388189574233897e-08+0j)\n",
      "   level =  2 (6.236361540769007e-09+0j)\n",
      "   level =  2 (5.5496780825043815e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (3.5449015436968077e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.9283368317799265e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.4783536032978375e-09+0j)\n",
      "   level =  2 RelRes (0.23705386444217305+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (1.0058762064288063e-08+0j)\n",
      "  level =  1 RelRes (0.15477285509337013+0j)\n",
      "  level 1   iter 4\n",
      "30_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.825932948703085e-07\n",
      " level =  0 (6.987344313878214e-08+0j)\n",
      "31_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):5.516898285613144e-08\n",
      "  level =  1 (4.214556130799165e-08+0j)\n",
      "  level =  1 (3.746198550480825e-08+0j)\n",
      "   level =  2 (1.888382011140296e-08+0j)\n",
      "   level =  2 (1.312241967037567e-08+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (9.34348695225906e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.2861024823243775e-09+0j)\n",
      "   level =  2 RelRes (0.1740168283185493+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (2.2955456842457384e-08+0j)\n",
      "   level =  2 (7.910931427263297e-09+0j)\n",
      "   level =  2 (5.727206592851281e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.316624448909026e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.1035170146870675e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21974982872050586+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.1260418264063653e-08+0j)\n",
      "   level =  2 (4.04422829479791e-09+0j)\n",
      "   level =  2 (3.6023313016887197e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.3020376521313596e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.2503363545589885e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (9.581152240306867e-10+0j)\n",
      "   level =  2 RelRes (0.23690928260976518+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (6.522754022180114e-09+0j)\n",
      "  level =  1 RelRes (0.1547672831905852+0j)\n",
      "  level 1   iter 4\n",
      "31_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.184053279655152e-07\n",
      " level =  0 (4.523368941026785e-08+0j)\n",
      "32_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):3.573735258857129e-08\n",
      "  level =  1 (2.7324253801577895e-08+0j)\n",
      "  level =  1 (2.428599993831438e-08+0j)\n",
      "   level =  2 (1.2249632084593469e-08+0j)\n",
      "   level =  2 (8.504444017377244e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.0656843208596056e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.129564457800645e-09+0j)\n",
      "   level =  2 RelRes (0.17384721786697802+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.4892077900314486e-08+0j)\n",
      "   level =  2 (5.132829215658704e-09+0j)\n",
      "   level =  2 (3.717125571934572e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.7927041931665197e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.3642032342941928e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21966552890740706+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (7.292714586058491e-09+0j)\n",
      "   level =  2 (2.6228270201353525e-09+0j)\n",
      "   level =  2 (2.337981299094756e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (1.4946113741083722e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (8.108599611066537e-10+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (6.21134373386051e-10+0j)\n",
      "   level =  2 RelRes (0.2368186573562129+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (4.2301934747390184e-09+0j)\n",
      "  level =  1 RelRes (0.15481460190853363+0j)\n",
      "  level 1   iter 4\n",
      "32_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):7.676941828862682e-08\n",
      " level =  0 (2.9284154334114577e-08+0j)\n",
      "33_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):2.3148467149026305e-08\n",
      "  level =  1 (1.7711833859124253e-08+0j)\n",
      "  level =  1 (1.5743275295864257e-08+0j)\n",
      "   level =  2 (7.94534363077328e-09+0j)\n",
      "   level =  2 (5.512228157881794e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.938998384389461e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.3801188186043677e-09+0j)\n",
      "   level =  2 RelRes (0.17370158960261958+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (9.662161012400992e-09+0j)\n",
      "   level =  2 (3.3305127725282275e-09+0j)\n",
      "   level =  2 (2.4122616776141457e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.8073126312759809e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (8.848742464847819e-10+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21957689380812684+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (4.723890276149166e-09+0j)\n",
      "   level =  2 (1.7009835590401648e-09+0j)\n",
      "   level =  2 (1.5171863403520177e-09+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (9.701108094083237e-10+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (5.258953198685217e-10+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (4.0274031525249833e-10+0j)\n",
      "   level =  2 RelRes (0.23676908169515617+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (2.7434496589677876e-09+0j)\n",
      "  level =  1 RelRes (0.1548935971728585+0j)\n",
      "  level 1   iter 4\n",
      "33_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):4.9767150602779773e-08\n",
      " level =  0 (1.8959688367761343e-08+0j)\n",
      "34_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):1.4993730533321648e-08\n",
      "  level =  1 (1.1479368228614544e-08+0j)\n",
      "  level =  1 (1.0204814660738982e-08+0j)\n",
      "   level =  2 (5.152860447335686e-09+0j)\n",
      "   level =  2 (3.572936966487455e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.55810431806585e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (8.944207091819046e-10+0j)\n",
      "   level =  2 RelRes (0.17357751453260675+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (6.2688193401419345e-09+0j)\n",
      "   level =  2 (2.160920963262641e-09+0j)\n",
      "   level =  2 (1.5652228044730587e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.1698468149778394e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (5.739814705647957e-10+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21949458785316725+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (3.060467063160961e-09+0j)\n",
      "   level =  2 (1.103079140543516e-09+0j)\n",
      "   level =  2 (9.84404325165416e-10+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (6.294841736064099e-10+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (3.410789844458623e-10+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (2.611523737914408e-10+0j)\n",
      "   level =  2 RelRes (0.23674853797232007+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (1.779178931147599e-09+0j)\n",
      "  level =  1 RelRes (0.15498927255531814+0j)\n",
      "  level 1   iter 4\n",
      "34_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):3.225844753923414e-08\n",
      " level =  0 (1.2276100177700474e-08+0j)\n",
      "35_B:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):9.711692304670732e-09\n",
      "  level =  1 (7.43922961554417e-09+0j)\n",
      "  level =  1 (6.614342495012406e-09+0j)\n",
      "   level =  2 (3.341389330434286e-09+0j)\n",
      "   level =  2 (2.3159063979682085e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.6611419350975543e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (5.796420288215489e-10+0j)\n",
      "   level =  2 RelRes (0.17347335838479255+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (4.066830994299863e-09+0j)\n",
      "   level =  2 (1.4018863180675148e-09+0j)\n",
      "   level =  2 (1.0154410782153597e-09+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (7.57334709523639e-10+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (3.723009829716405e-10+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 RelRes (0.21942342678452398+0j)\n",
      "   level 2   iter 3\n",
      "  level =  1 (1.9830687932377926e-09+0j)\n",
      "   level =  2 (7.152836097798521e-10+0j)\n",
      "   level =  2 (6.386196441793483e-10+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (4.0834479920788925e-10+0j)\n",
      "    level 3   iter 2\n",
      "   level =  2 (2.2120320117999577e-10+0j)\n",
      "    level 3   iter 3\n",
      "   level =  2 (1.6934185607652146e-10+0j)\n",
      "   level =  2 RelRes (0.2367478490505899+0j)\n",
      "   level 2   iter 4\n",
      "  level =  1 (1.1537592637800468e-09+0j)\n",
      "  level =  1 RelRes (0.15509122898549638+0j)\n",
      "  level 1   iter 4\n",
      "35_F:np.linalg.norm(b - apply_mat(x, self.mg_ops[0])):2.0907366043388896e-08\n",
      " level =  0 (7.949145323884351e-09+0j)\n",
      " level =  0 RelRes (5.963078777471461e-11+0j)\n",
      "mg_bicgstab_recursive.count =  37\n",
      "Execution time: 13.372499883000273 seconds\n",
      "(7.655587275223752e-11-2.7997160145787348e-11j)\n",
      "(4.5971788160348304e-05-6.394686951072259e-07j)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "V1 = my_mg.mg_bicgstab(Vout, tol=1e-8)\n",
    "end_time = time.perf_counter()\n",
    "my_mg.plot()\n",
    "print(f\"Execution time: {end_time - start_time} seconds\")\n",
    "print(V[0, 0, 0] - V1[0, 0, 0])\n",
    "print(V[0, 0, 0] - V0[0, 0, 0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c945f163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_mg.mg_ops[0].nx:64\n",
      "my_mg.mg_ops[0].ny:64\n",
      "my_mg.mg_ops[0].nc:2\n",
      "my_mg.mg_ops[1].nx:16\n",
      "my_mg.mg_ops[1].ny:16\n",
      "my_mg.mg_ops[1].nc:8\n",
      "my_mg.mg_ops[2].nx:8\n",
      "my_mg.mg_ops[2].ny:8\n",
      "my_mg.mg_ops[2].nc:12\n",
      "my_mg.mg_ops[3].nx:4\n",
      "my_mg.mg_ops[3].ny:4\n",
      "my_mg.mg_ops[3].nc:12\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(my_mg.mg_ops)):\n",
    "    print(f\"my_mg.mg_ops[{i}].nx:{my_mg.mg_ops[i].nx}\")\n",
    "    print(f\"my_mg.mg_ops[{i}].ny:{my_mg.mg_ops[i].ny}\")\n",
    "    print(f\"my_mg.mg_ops[{i}].nc:{my_mg.mg_ops[i].nc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de04ae32",
   "metadata": {},
   "outputs": [],
   "source": [
    "index=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24629e2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_mg.mg_ops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18cc0c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_mg.R_null_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b4f5f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.28063894+0.22651623j,  0.02760367+0.15023523j,\n",
       "        -0.02487521+0.06406838j, ..., -0.00359013+0.00158974j,\n",
       "         0.00150504+0.00563582j,  0.00311149+0.00465684j],\n",
       "       [-0.02443388+0.0189165j ,  0.08047871-0.06762424j,\n",
       "         0.06865845+0.02531214j, ...,  0.03774894+0.02290687j,\n",
       "        -0.00409989-0.05330934j, -0.03627082-0.02294739j],\n",
       "       [-0.23545413+0.04932522j,  0.17485137+0.17903859j,\n",
       "        -0.0870982 -0.02250805j, ...,  0.01706256+0.05535219j,\n",
       "        -0.06842313-0.02827155j, -0.06562199-0.00132637j],\n",
       "       ...,\n",
       "       [-0.00761738+0.02497323j,  0.18002916-0.06855444j,\n",
       "         0.15794371-0.04642197j, ...,  0.06523266-0.00262967j,\n",
       "         0.00178109-0.034711j  , -0.03427244+0.03848846j],\n",
       "       [-0.12363708+0.02793598j,  0.04772247-0.03919286j,\n",
       "         0.25751467+0.15432695j, ..., -0.0332755 +0.03798029j,\n",
       "        -0.02974017+0.03803465j, -0.00992414+0.02619749j],\n",
       "       [ 0.1585119 -0.14868994j, -0.19093633-0.10670232j,\n",
       "         0.10824048+0.01209653j, ...,  0.08830533+0.0773872j ,\n",
       "         0.00733372+0.02899283j, -0.05822746+0.02563187j]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_mg.R_null_vec[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
