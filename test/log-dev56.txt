Rank7-Error: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Using device: cpu
@My Rank:7/8, Local Rank:7@

Using device: cpu
@My Rank:0/8, Local Rank:0@

Rank3-Error: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Using device: cpu
@My Rank:3/8, Local Rank:3@

Rank2-Error: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Rank6-Error: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Rank1-Error: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Using device: cpu
@My Rank:2/8, Local Rank:2@

Using device: cpu
@My Rank:1/8, Local Rank:1@

Using device: cpu
@My Rank:6/8, Local Rank:6@

Rank4-Error: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Rank5-Error: CUDA error: invalid device ordinal
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Using device: cpu
@My Rank:4/8, Local Rank:4@

Using device: cpu
@My Rank:5/8, Local Rank:5@

rank 0: Data is load from test.ascend-dev56-x.h5
rank 6: Data is load from test.ascend-dev56-x.h5
rank 4: Data is load from test.ascend-dev56-x.h5
rank 5: Data is load from test.ascend-dev56-x.h5
rank 7: Data is load from test.ascend-dev56-x.h5
rank 1: Data is load from test.ascend-dev56-x.h5
rank 3: Data is load from test.ascend-dev56-x.h5
rank 2: Data is load from test.ascend-dev56-x.h5
rank 6: Data is load from test.ascend-dev56-b.h5
rank 3: Data is load from test.ascend-dev56-b.h5
rank 2: Data is load from test.ascend-dev56-b.h5
rank 7: Data is load from test.ascend-dev56-b.h5
rank 0: Data is load from test.ascend-dev56-b.h5
rank 5: Data is load from test.ascend-dev56-b.h5
rank 1: Data is load from test.ascend-dev56-b.h5
rank 4: Data is load from test.ascend-dev56-b.h5
rank 2: Data is load from test.ascend-dev56-U.h5
rank 7: Data is load from test.ascend-dev56-U.h5
rank 1: Data is load from test.ascend-dev56-U.h5
rank 0: Data is load from test.ascend-dev56-U.h5
rank 4: Data is load from test.ascend-dev56-U.h5
rank 6: Data is load from test.ascend-dev56-U.h5
rank 5: Data is load from test.ascend-dev56-U.h5
rank 3: Data is load from test.ascend-dev56-U.h5
rank 2: Data is load from test.ascend-dev56-clover_term.h5
rank 3: Data is load from test.ascend-dev56-clover_term.h5
rank 0: Data is load from test.ascend-dev56-clover_term.h5
rank 7: Data is load from test.ascend-dev56-clover_term.h5
rank 6: Data is load from test.ascend-dev56-clover_term.h5
rank 4: Data is load from test.ascend-dev56-clover_term.h5
rank 1: Data is load from test.ascend-dev56-clover_term.h5
rank 5: Data is load from test.ascend-dev56-clover_term.h5
Building grid list:
  Level 0: 8x8x8x8
  Level 1: 4x4x4x4
  Level 2: 2x2x2x2
self.grid_list:[[8, 8, 8, 8], [4, 4, 4, 4], [2, 2, 2, 2]]

Performance Statistics:
Total iterations: 79
Total time: 1.667760 seconds
Average time per iteration: 0.021108 s
Final residual: 5.07e-07

Performance Statistics:
Total time: 1.680289 seconds

Performance Statistics:
Total iterations: 79
Total time: 1.667760 seconds
Average time per iteration: 0.021109 s
Final residual: 5.07e-07

Performance Statistics:
Total time: 1.678733 seconds

Performance Statistics:
Total iterations: 79
Total time: 1.667777 seconds
Average time per iteration: 0.021109 s
Final residual: 5.07e-07

Performance Statistics:
Total time: 1.678604 seconds

Performance Statistics:
Total iterations: 79
Total time: 1.667750 seconds
Average time per iteration: 0.021108 s
Final residual: 5.07e-07

Performance Statistics:
Total time: 1.680172 seconds

Performance Statistics:
Total iterations: 79
Total time: 1.667738 seconds
Average time per iteration: 0.021108 s
Final residual: 5.07e-07

Performance Statistics:
Total time: 1.679816 seconds

Performance Statistics:
Total iterations: 79
Total time: 1.667586 seconds
Average time per iteration: 0.021106 s
Final residual: 5.07e-07

Performance Statistics:
Total time: 1.680106 seconds

Performance Statistics:
Total iterations: 79
Total time: 1.667816 seconds
Average time per iteration: 0.021109 s
Final residual: 5.07e-07

Performance Statistics:
Total time: 1.680306 seconds

Performance Statistics:
Total iterations: 79
Total time: 1.667751 seconds
Average time per iteration: 0.021108 s
Final residual: 5.07e-07

Performance Statistics:
Total time: 1.680070 seconds
torch.norm(self.refer_x-self.x).item()/torch.norm(self.x).item(): 2.384353535068239e-08
torch.norm(self.refer_x-self.x).item()/torch.norm(self.x).item(): 2.362906470039869e-08
torch.norm(self.refer_x-self.x).item()/torch.norm(self.x).item(): 2.492586741208808e-08
torch.norm(self.refer_x-self.x).item()/torch.norm(self.x).item(): 2.5262555868962683e-08
torch.norm(self.refer_x-self.x).item()/torch.norm(self.x).item(): 2.5821624882239697e-08
torch.norm(self.refer_x-self.x).item()/torch.norm(self.x).item(): 2.378143195770221e-08
torch.norm(self.refer_x-self.x).item()/torch.norm(self.x).item(): 2.3261675794316408e-08
torch.norm(self.b): 78.56186895267099
torch.norm(self.x): 96.60717399507955
torch.norm(_full_b): 221.39057988095328
torch.norm(_full_x): 272.6366621132508
torch.norm(full_Ax): 221.3905798816257
torch.norm(_full_Ax): 221.3905798816257
torch.norm(full_Ax-_full_b).item()/torch.norm(full_Ax).item(): 2.291509536796674e-09
torch.norm(_full_Ax-_full_b).item()/torch.norm(_full_Ax).item(): 2.2915095380785662e-09
torch.norm(full_Ax-_full_Ax).item()/torch.norm(full_Ax).item(): 2.243018487189114e-16
torch.norm(self.refer_x-self.x).item()/torch.norm(self.x).item(): 2.2927423621570994e-08
